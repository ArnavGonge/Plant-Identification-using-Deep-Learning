{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import EfficientNetB0, efficientnet_v2, EfficientNetB1\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback, EarlyStopping\n",
    "from keras.optimizers import Adam, Adagrad, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24061 validated image filenames belonging to 588 classes.\n",
      "Found 6145 validated image filenames belonging to 588 classes.\n"
     ]
    }
   ],
   "source": [
    "# Paths to the CSV files (Update these paths)\n",
    "train_csv_file = \"/home/halwa/fyp/Training/train2.csv\"\n",
    "validation_csv_file = \"/home/halwa/fyp/Training/validation2.csv\"\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "\n",
    "# Create an ImageDataGenerator with augmentation for training\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create a generator for loading and preprocessing training images with augmentation\n",
    "trainGen = trainAug.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(train_csv_file, encoding='ISO-8859-1'),\n",
    "    x_col='Image_Path',\n",
    "    y_col='Species',\n",
    "    target_size=(240, 240),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create a generator for loading and preprocessing validation images in smaller batches\n",
    "valAug = ImageDataGenerator(rescale=1.0/255.0)\n",
    "valGen = valAug.flow_from_dataframe(\n",
    "    dataframe=pd.read_csv(validation_csv_file, encoding='ISO-8859-1'),\n",
    "    x_col='Image_Path',\n",
    "    y_col='Species',\n",
    "    target_size=(240, 240),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class indices\n",
    "class_indices = trainGen.class_indices\n",
    "\n",
    "# Create a DataFrame from class indices\n",
    "df = pd.DataFrame(list(class_indices.items()), columns=['Class', 'Index'])\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "csv_file_path = '/home/halwa/fyp/Training/class_indices.csv'\n",
    "\n",
    "# Write class indices to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha values:\n",
      "Class 0: 0.00036313605960458517\n",
      "Class 1: 0.0006911298842169344\n",
      "Class 2: 0.00013064040103927255\n",
      "Class 3: 0.0001575369678903371\n",
      "Class 4: 0.00037587765837088227\n",
      "Class 5: 8.570010686526075e-05\n",
      "Class 6: 0.0002856670180335641\n",
      "Class 7: 0.0001575369678903371\n",
      "Class 8: 0.0014283350901678205\n",
      "Class 9: 0.00036939702113159\n",
      "Class 10: 8.927094313548878e-05\n",
      "Class 11: 0.0003512299444992095\n",
      "Class 12: 0.0005493596545420587\n",
      "Class 13: 8.570010686526075e-05\n",
      "Class 14: 0.00030176094151102006\n",
      "Class 15: 0.00014878490765113384\n",
      "Class 16: 8.570010686526075e-05\n",
      "Class 17: 0.0006695321062579751\n",
      "Class 18: 0.0013390642125159502\n",
      "Class 19: 8.570010686526075e-05\n",
      "Class 20: 0.00014878490765113384\n",
      "Class 21: 0.00015638706099707633\n",
      "Class 22: 0.00014188759087119251\n",
      "Class 23: 0.00010350254160584882\n",
      "Class 24: 0.0006695321062579751\n",
      "Class 25: 0.0006121436017565429\n",
      "Class 26: 0.0021425026934593916\n",
      "Class 27: 0.00015088047075551003\n",
      "Class 28: 0.00045585163752548397\n",
      "Class 29: 0.00011217291466891766\n",
      "Class 30: 6.532020051963627e-05\n",
      "Class 31: 0.0005951396306045353\n",
      "Class 32: 0.001785418950021267\n",
      "Class 33: 8.570010686526075e-05\n",
      "Class 34: 0.0001158109589596279\n",
      "Class 35: 0.00022552660084329545\n",
      "Class 36: 0.00012829357001464814\n",
      "Class 37: 0.0023805585224181414\n",
      "Class 38: 0.00029756981530226767\n",
      "Class 39: 0.0006911298842169344\n",
      "Class 40: 0.004285005386918783\n",
      "Class 41: 0.000151950545841828\n",
      "Class 42: 0.00023805585806258023\n",
      "Class 43: 8.570010686526075e-05\n",
      "Class 44: 0.001648079021833837\n",
      "Class 45: 0.004285005386918783\n",
      "Class 46: 0.0026781284250319004\n",
      "Class 47: 0.0023805585224181414\n",
      "Class 48: 0.00010011694394052029\n",
      "Class 49: 0.0007141675450839102\n",
      "Class 50: 0.00022087656543590128\n",
      "Class 51: 0.00015413688379339874\n",
      "Class 52: 0.0010712513467296958\n",
      "Class 53: 0.00010659217514330521\n",
      "Class 54: 0.0005638165166601539\n",
      "Class 55: 0.00022552660084329545\n",
      "Class 56: 0.0014283350901678205\n",
      "Class 57: 0.00011158868437632918\n",
      "Class 58: 0.00014476368960458785\n",
      "Class 59: 0.00031977653270587325\n",
      "Class 60: 0.0004982564132660627\n",
      "Class 61: 0.0030607180669903755\n",
      "Class 62: 0.0026781284250319004\n",
      "Class 63: 0.00010502464283490553\n",
      "Class 64: 0.0026781284250319004\n",
      "Class 65: 0.00046576146269217134\n",
      "Class 66: 0.0005790547584183514\n",
      "Class 67: 9.396941459272057e-05\n",
      "Class 68: 0.0026781284250319004\n",
      "Class 69: 0.001785418950021267\n",
      "Class 70: 0.00020404787210281938\n",
      "Class 71: 0.001785418950021267\n",
      "Class 72: 0.004285005386918783\n",
      "Class 73: 0.0010712513467296958\n",
      "Class 74: 0.0009315229253843427\n",
      "Class 75: 0.0006911298842169344\n",
      "Class 76: 0.00018156802980229259\n",
      "Class 77: 0.0005493596545420587\n",
      "Class 78: 0.0004982564132660627\n",
      "Class 79: 0.001648079021833837\n",
      "Class 80: 0.0008927094750106335\n",
      "Class 81: 0.0030607180669903755\n",
      "Class 82: 0.00019129487918689847\n",
      "Class 83: 0.00022317736875265837\n",
      "Class 84: 8.570010686526075e-05\n",
      "Class 85: 8.63912355271168e-05\n",
      "Class 86: 0.0007651795167475939\n",
      "Class 87: 0.00030176094151102006\n",
      "Class 88: 0.001648079021833837\n",
      "Class 89: 0.001785418950021267\n",
      "Class 90: 0.0011276330333203077\n",
      "Class 91: 8.084916044026613e-05\n",
      "Class 92: 0.00011644036567304283\n",
      "Class 93: 0.0012602957431226969\n",
      "Class 94: 0.0010712513467296958\n",
      "Class 95: 0.0005790547584183514\n",
      "Class 96: 0.0006911298842169344\n",
      "Class 97: 0.0001575369678903371\n",
      "Class 98: 0.0026781284250319004\n",
      "Class 99: 0.0023805585224181414\n",
      "Class 100: 0.00073879404226318\n",
      "Class 101: 0.00015413688379339874\n",
      "Class 102: 0.0013390642125159502\n",
      "Class 103: 0.00016480790509376675\n",
      "Class 104: 0.0007141675450839102\n",
      "Class 105: 0.0002581328444648534\n",
      "Class 106: 0.0003455649421084672\n",
      "Class 107: 0.0010712513467296958\n",
      "Class 108: 0.00020600987772922963\n",
      "Class 109: 0.00073879404226318\n",
      "Class 110: 0.0006911298842169344\n",
      "Class 111: 0.00023805585806258023\n",
      "Class 112: 8.570010686526075e-05\n",
      "Class 113: 0.00011335992894601077\n",
      "Class 114: 0.0010202393168583512\n",
      "Class 115: 0.0011902792612090707\n",
      "Class 116: 0.00012984864588361233\n",
      "Class 117: 0.00038258975837379694\n",
      "Class 118: 0.0026781284250319004\n",
      "Class 119: 0.0015303590334951878\n",
      "Class 120: 0.0014283350901678205\n",
      "Class 121: 0.0013390642125159502\n",
      "Class 122: 0.0019477297319099307\n",
      "Class 123: 0.0008570010541006923\n",
      "Class 124: 0.00038954595220275223\n",
      "Class 125: 0.001785418950021267\n",
      "Class 126: 0.00011043828271795064\n",
      "Class 127: 0.0003296158101875335\n",
      "Class 128: 0.0001575369678903371\n",
      "Class 129: 0.0009315229253843427\n",
      "Class 130: 0.0005951396306045353\n",
      "Class 131: 0.00029756981530226767\n",
      "Class 132: 0.0021425026934593916\n",
      "Class 133: 0.00029756981530226767\n",
      "Class 134: 0.0008240395109169185\n",
      "Class 135: 0.0007651795167475939\n",
      "Class 136: 0.00024912820663303137\n",
      "Class 137: 0.0030607180669903755\n",
      "Class 138: 0.0021425026934593916\n",
      "Class 139: 0.0030607180669903755\n",
      "Class 140: 0.0026781284250319004\n",
      "Class 141: 0.0005493596545420587\n",
      "Class 142: 0.0009738648659549654\n",
      "Class 143: 0.00015988826635293663\n",
      "Class 144: 0.0007651795167475939\n",
      "Class 145: 0.0030607180669903755\n",
      "Class 146: 0.0019477297319099307\n",
      "Class 147: 0.00036313605960458517\n",
      "Class 148: 0.00024626468075439334\n",
      "Class 149: 0.0009315229253843427\n",
      "Class 150: 0.0002645064960233867\n",
      "Class 151: 0.0010712513467296958\n",
      "Class 152: 0.0023805585224181414\n",
      "Class 153: 0.00020404787210281938\n",
      "Class 154: 0.0008570010541006923\n",
      "Class 155: 0.0014283350901678205\n",
      "Class 156: 0.00019301826250739396\n",
      "Class 157: 0.001785418950021267\n",
      "Class 158: 0.0030607180669903755\n",
      "Class 159: 0.00036313605960458517\n",
      "Class 160: 0.00017561497224960476\n",
      "Class 161: 0.0006695321062579751\n",
      "Class 162: 0.00042009857133962214\n",
      "Class 163: 0.0021425026934593916\n",
      "Class 164: 0.00037587765837088227\n",
      "Class 165: 0.0023805585224181414\n",
      "Class 166: 0.0009738648659549654\n",
      "Class 167: 0.00013474859588313848\n",
      "Class 168: 0.00038258975837379694\n",
      "Class 169: 0.0002303766377735883\n",
      "Class 170: 0.0005790547584183514\n",
      "Class 171: 0.00038954595220275223\n",
      "Class 172: 0.004285005386918783\n",
      "Class 173: 0.0012602957431226969\n",
      "Class 174: 0.0008927094750106335\n",
      "Class 175: 0.00021004928566981107\n",
      "Class 176: 0.0026781284250319004\n",
      "Class 177: 0.0010712513467296958\n",
      "Class 178: 0.0008240395109169185\n",
      "Class 179: 0.0012602957431226969\n",
      "Class 180: 0.0011276330333203077\n",
      "Class 181: 0.00021004928566981107\n",
      "Class 182: 0.00073879404226318\n",
      "Class 183: 0.0015303590334951878\n",
      "Class 184: 0.0010712513467296958\n",
      "Class 185: 0.0010712513467296958\n",
      "Class 186: 0.0003967597440350801\n",
      "Class 187: 0.00034007980138994753\n",
      "Class 188: 0.001785418950021267\n",
      "Class 189: 0.0030607180669903755\n",
      "Class 190: 0.0001575369678903371\n",
      "Class 191: 0.0012602957431226969\n",
      "Class 192: 0.00041201975545845926\n",
      "Class 193: 0.0030607180669903755\n",
      "Class 194: 0.0023805585224181414\n",
      "Class 195: 0.0006121436017565429\n",
      "Class 196: 0.0019477297319099307\n",
      "Class 197: 0.0019477297319099307\n",
      "Class 198: 0.0026781284250319004\n",
      "Class 199: 0.0019477297319099307\n",
      "Class 200: 0.0021425026934593916\n",
      "Class 201: 0.0010712513467296958\n",
      "Class 202: 0.0010712513467296958\n",
      "Class 203: 0.00016480790509376675\n",
      "Class 204: 0.0005638165166601539\n",
      "Class 205: 0.0003512299444992095\n",
      "Class 206: 0.00021004928566981107\n",
      "Class 207: 0.0007141675450839102\n",
      "Class 208: 0.0021425026934593916\n",
      "Class 209: 0.00073879404226318\n",
      "Class 210: 0.0021425026934593916\n",
      "Class 211: 0.001785418950021267\n",
      "Class 212: 0.0012602957431226969\n",
      "Class 213: 0.0003967597440350801\n",
      "Class 214: 0.004285005386918783\n",
      "Class 215: 0.00045585163752548397\n",
      "Class 216: 0.0001575369678903371\n",
      "Class 217: 0.0011902792612090707\n",
      "Class 218: 0.0010202393168583512\n",
      "Class 219: 0.00038258975837379694\n",
      "Class 220: 0.0003150739357806742\n",
      "Class 221: 0.00024912820663303137\n",
      "Class 222: 0.00031050763209350407\n",
      "Class 223: 0.0013390642125159502\n",
      "Class 224: 0.00044635473750531673\n",
      "Class 225: 0.00047611171612516046\n",
      "Class 226: 0.0023805585224181414\n",
      "Class 227: 0.0012602957431226969\n",
      "Class 228: 0.0011902792612090707\n",
      "Class 229: 0.00015638706099707633\n",
      "Class 230: 0.001785418950021267\n",
      "Class 231: 0.001648079021833837\n",
      "Class 232: 0.00034007980138994753\n",
      "Class 233: 0.0006911298842169344\n",
      "Class 234: 0.0007141675450839102\n",
      "Class 235: 0.0023805585224181414\n",
      "Class 236: 9.438338020117953e-05\n",
      "Class 237: 0.0030607180669903755\n",
      "Class 238: 0.00042850052705034614\n",
      "Class 239: 0.0013390642125159502\n",
      "Class 240: 0.0023805585224181414\n",
      "Class 241: 0.00038258975837379694\n",
      "Class 242: 0.004285005386918783\n",
      "Class 243: 0.0012602957431226969\n",
      "Class 244: 0.0009315229253843427\n",
      "Class 245: 0.0014283350901678205\n",
      "Class 246: 0.0023805585224181414\n",
      "Class 247: 0.0008240395109169185\n",
      "Class 248: 0.0013390642125159502\n",
      "Class 249: 0.0009738648659549654\n",
      "Class 250: 0.003570837900042534\n",
      "Class 251: 0.0006911298842169344\n",
      "Class 252: 0.0026781284250319004\n",
      "Class 253: 0.0012602957431226969\n",
      "Class 254: 0.00022792581876274198\n",
      "Class 255: 0.0012602957431226969\n",
      "Class 256: 0.0008570010541006923\n",
      "Class 257: 0.0021425026934593916\n",
      "Class 258: 0.0013390642125159502\n",
      "Class 259: 0.0019477297319099307\n",
      "Class 260: 0.0005790547584183514\n",
      "Class 261: 0.0023805585224181414\n",
      "Class 262: 0.003570837900042534\n",
      "Class 263: 0.001648079021833837\n",
      "Class 264: 0.0030607180669903755\n",
      "Class 265: 0.0010712513467296958\n",
      "Class 266: 0.0013390642125159502\n",
      "Class 267: 0.0030607180669903755\n",
      "Class 268: 0.0014283350901678205\n",
      "Class 269: 0.0021425026934593916\n",
      "Class 270: 0.004285005386918783\n",
      "Class 271: 0.0005493596545420587\n",
      "Class 272: 0.0010712513467296958\n",
      "Class 273: 0.0011902792612090707\n",
      "Class 274: 0.0012602957431226969\n",
      "Class 275: 0.0026781284250319004\n",
      "Class 276: 0.0012602957431226969\n",
      "Class 277: 0.0004982564132660627\n",
      "Class 278: 0.0019477297319099307\n",
      "Class 279: 0.0021425026934593916\n",
      "Class 280: 0.0015303590334951878\n",
      "Class 281: 0.0019477297319099307\n",
      "Class 282: 0.0006121436017565429\n",
      "Class 283: 0.0005493596545420587\n",
      "Class 284: 0.0006911298842169344\n",
      "Class 285: 0.0014283350901678205\n",
      "Class 286: 0.0006492432439699769\n",
      "Class 287: 0.0015303590334951878\n",
      "Class 288: 0.001785418950021267\n",
      "Class 289: 0.0023805585224181414\n",
      "Class 290: 0.004285005386918783\n",
      "Class 291: 0.004285005386918783\n",
      "Class 292: 0.004285005386918783\n",
      "Class 293: 0.0014283350901678205\n",
      "Class 294: 0.0010712513467296958\n",
      "Class 295: 0.0023805585224181414\n",
      "Class 296: 0.00027467982727102935\n",
      "Class 297: 0.0026781284250319004\n",
      "Class 298: 0.0030607180669903755\n",
      "Class 299: 0.0026781284250319004\n",
      "Class 300: 0.0019477297319099307\n",
      "Class 301: 0.004285005386918783\n",
      "Class 302: 0.0005790547584183514\n",
      "Class 303: 0.0009738648659549654\n",
      "Class 304: 0.00017003990069497377\n",
      "Class 305: 0.0012602957431226969\n",
      "Class 306: 0.001785418950021267\n",
      "Class 307: 0.003570837900042534\n",
      "Class 308: 0.003570837900042534\n",
      "Class 309: 0.0004982564132660627\n",
      "Class 310: 0.0015303590334951878\n",
      "Class 311: 0.0026781284250319004\n",
      "Class 312: 0.0006492432439699769\n",
      "Class 313: 0.0006121436017565429\n",
      "Class 314: 0.001785418950021267\n",
      "Class 315: 0.0019477297319099307\n",
      "Class 316: 0.0023805585224181414\n",
      "Class 317: 0.0014283350901678205\n",
      "Class 318: 0.0023805585224181414\n",
      "Class 319: 0.0021425026934593916\n",
      "Class 320: 0.0026781284250319004\n",
      "Class 321: 0.0019477297319099307\n",
      "Class 322: 0.0015303590334951878\n",
      "Class 323: 0.0009315229253843427\n",
      "Class 324: 0.0026781284250319004\n",
      "Class 325: 0.0009738648659549654\n",
      "Class 326: 0.0023805585224181414\n",
      "Class 327: 0.0015303590334951878\n",
      "Class 328: 0.004285005386918783\n",
      "Class 329: 0.0005951396306045353\n",
      "Class 330: 0.0012602957431226969\n",
      "Class 331: 0.004285005386918783\n",
      "Class 332: 0.004285005386918783\n",
      "Class 333: 0.00023543986026197672\n",
      "Class 334: 0.0015303590334951878\n",
      "Class 335: 0.001648079021833837\n",
      "Class 336: 0.001785418950021267\n",
      "Class 337: 0.004285005386918783\n",
      "Class 338: 0.0015303590334951878\n",
      "Class 339: 0.003570837900042534\n",
      "Class 340: 0.0019477297319099307\n",
      "Class 341: 0.003570837900042534\n",
      "Class 342: 0.001648079021833837\n",
      "Class 343: 0.0012602957431226969\n",
      "Class 344: 0.001785418950021267\n",
      "Class 345: 0.0010202393168583512\n",
      "Class 346: 0.0013390642125159502\n",
      "Class 347: 0.003570837900042534\n",
      "Class 348: 0.0030607180669903755\n",
      "Class 349: 0.00015870390052441508\n",
      "Class 350: 0.0003967597440350801\n",
      "Class 351: 0.001648079021833837\n",
      "Class 352: 0.0011902792612090707\n",
      "Class 353: 0.0026781284250319004\n",
      "Class 354: 0.0021425026934593916\n",
      "Class 355: 0.004285005386918783\n",
      "Class 356: 0.0005225616041570902\n",
      "Class 357: 0.00046576146269217134\n",
      "Class 358: 0.003570837900042534\n",
      "Class 359: 0.0030607180669903755\n",
      "Class 360: 0.0007141675450839102\n",
      "Class 361: 0.003570837900042534\n",
      "Class 362: 0.0021425026934593916\n",
      "Class 363: 0.001648079021833837\n",
      "Class 364: 0.0019477297319099307\n",
      "Class 365: 0.0030607180669903755\n",
      "Class 366: 0.0026781284250319004\n",
      "Class 367: 0.00046576146269217134\n",
      "Class 368: 0.0021425026934593916\n",
      "Class 369: 0.0012602957431226969\n",
      "Class 370: 0.0021425026934593916\n",
      "Class 371: 0.003570837900042534\n",
      "Class 372: 0.001785418950021267\n",
      "Class 373: 0.001785418950021267\n",
      "Class 374: 0.0021425026934593916\n",
      "Class 375: 0.0030607180669903755\n",
      "Class 376: 0.0021425026934593916\n",
      "Class 377: 0.0015303590334951878\n",
      "Class 378: 0.0026781284250319004\n",
      "Class 379: 0.0026781284250319004\n",
      "Class 380: 0.0026781284250319004\n",
      "Class 381: 0.003570837900042534\n",
      "Class 382: 0.0012602957431226969\n",
      "Class 383: 0.001648079021833837\n",
      "Class 384: 0.0030607180669903755\n",
      "Class 385: 0.0026781284250319004\n",
      "Class 386: 0.0006301478715613484\n",
      "Class 387: 0.0014283350901678205\n",
      "Class 388: 0.0019477297319099307\n",
      "Class 389: 0.004285005386918783\n",
      "Class 390: 0.0012602957431226969\n",
      "Class 391: 0.0023805585224181414\n",
      "Class 392: 0.0021425026934593916\n",
      "Class 393: 0.0026781284250319004\n",
      "Class 394: 0.0026781284250319004\n",
      "Class 395: 0.0030607180669903755\n",
      "Class 396: 0.0019477297319099307\n",
      "Class 397: 0.0023805585224181414\n",
      "Class 398: 0.003570837900042534\n",
      "Class 399: 0.0014283350901678205\n",
      "Class 400: 0.0010202393168583512\n",
      "Class 401: 0.0006911298842169344\n",
      "Class 402: 0.0023805585224181414\n",
      "Class 403: 0.001785418950021267\n",
      "Class 404: 0.0023805585224181414\n",
      "Class 405: 0.003570837900042534\n",
      "Class 406: 0.0021425026934593916\n",
      "Class 407: 0.0026781284250319004\n",
      "Class 408: 0.0014283350901678205\n",
      "Class 409: 0.0021425026934593916\n",
      "Class 410: 0.0026781284250319004\n",
      "Class 411: 0.003570837900042534\n",
      "Class 412: 0.004285005386918783\n",
      "Class 413: 0.004285005386918783\n",
      "Class 414: 0.0014283350901678205\n",
      "Class 415: 0.001785418950021267\n",
      "Class 416: 0.0015303590334951878\n",
      "Class 417: 0.004285005386918783\n",
      "Class 418: 0.004285005386918783\n",
      "Class 419: 0.0023805585224181414\n",
      "Class 420: 0.003570837900042534\n",
      "Class 421: 0.004285005386918783\n",
      "Class 422: 0.0019477297319099307\n",
      "Class 423: 0.004285005386918783\n",
      "Class 424: 0.004285005386918783\n",
      "Class 425: 0.0023805585224181414\n",
      "Class 426: 0.0023805585224181414\n",
      "Class 427: 0.0021425026934593916\n",
      "Class 428: 0.0010202393168583512\n",
      "Class 429: 0.0026781284250319004\n",
      "Class 430: 0.001785418950021267\n",
      "Class 431: 0.0030607180669903755\n",
      "Class 432: 0.003570837900042534\n",
      "Class 433: 0.004285005386918783\n",
      "Class 434: 0.0023805585224181414\n",
      "Class 435: 0.0011276330333203077\n",
      "Class 436: 0.0014283350901678205\n",
      "Class 437: 0.0030607180669903755\n",
      "Class 438: 0.004285005386918783\n",
      "Class 439: 0.0026781284250319004\n",
      "Class 440: 0.0023805585224181414\n",
      "Class 441: 0.0012602957431226969\n",
      "Class 442: 0.003570837900042534\n",
      "Class 443: 0.0014283350901678205\n",
      "Class 444: 0.0023805585224181414\n",
      "Class 445: 0.001648079021833837\n",
      "Class 446: 0.0026781284250319004\n",
      "Class 447: 0.0013390642125159502\n",
      "Class 448: 0.001785418950021267\n",
      "Class 449: 0.004285005386918783\n",
      "Class 450: 0.004285005386918783\n",
      "Class 451: 0.003570837900042534\n",
      "Class 452: 0.0023805585224181414\n",
      "Class 453: 0.0023805585224181414\n",
      "Class 454: 0.003570837900042534\n",
      "Class 455: 0.0023805585224181414\n",
      "Class 456: 0.003570837900042534\n",
      "Class 457: 0.0026781284250319004\n",
      "Class 458: 0.0030607180669903755\n",
      "Class 459: 0.0026781284250319004\n",
      "Class 460: 0.004285005386918783\n",
      "Class 461: 0.0011902792612090707\n",
      "Class 462: 0.0011902792612090707\n",
      "Class 463: 0.0019477297319099307\n",
      "Class 464: 0.0014283350901678205\n",
      "Class 465: 0.003570837900042534\n",
      "Class 466: 0.0013390642125159502\n",
      "Class 467: 0.003570837900042534\n",
      "Class 468: 0.0023805585224181414\n",
      "Class 469: 0.0021425026934593916\n",
      "Class 470: 0.0030607180669903755\n",
      "Class 471: 0.003570837900042534\n",
      "Class 472: 0.0023805585224181414\n",
      "Class 473: 0.0030607180669903755\n",
      "Class 474: 0.0026781284250319004\n",
      "Class 475: 0.0014283350901678205\n",
      "Class 476: 0.0023805585224181414\n",
      "Class 477: 0.0021425026934593916\n",
      "Class 478: 0.001648079021833837\n",
      "Class 479: 0.003570837900042534\n",
      "Class 480: 0.003570837900042534\n",
      "Class 481: 0.003570837900042534\n",
      "Class 482: 0.0023805585224181414\n",
      "Class 483: 0.001785418950021267\n",
      "Class 484: 0.003570837900042534\n",
      "Class 485: 0.004285005386918783\n",
      "Class 486: 0.003570837900042534\n",
      "Class 487: 0.0021425026934593916\n",
      "Class 488: 0.0014283350901678205\n",
      "Class 489: 0.004285005386918783\n",
      "Class 490: 0.0030607180669903755\n",
      "Class 491: 0.004285005386918783\n",
      "Class 492: 0.001648079021833837\n",
      "Class 493: 0.004285005386918783\n",
      "Class 494: 0.003570837900042534\n",
      "Class 495: 0.003570837900042534\n",
      "Class 496: 0.003570837900042534\n",
      "Class 497: 0.0023805585224181414\n",
      "Class 498: 0.004285005386918783\n",
      "Class 499: 0.0030607180669903755\n",
      "Class 500: 0.001785418950021267\n",
      "Class 501: 0.003570837900042534\n",
      "Class 502: 0.0030607180669903755\n",
      "Class 503: 0.0030607180669903755\n",
      "Class 504: 0.0013390642125159502\n",
      "Class 505: 0.0030607180669903755\n",
      "Class 506: 0.003570837900042534\n",
      "Class 507: 0.004285005386918783\n",
      "Class 508: 0.004285005386918783\n",
      "Class 509: 0.0023805585224181414\n",
      "Class 510: 0.0026781284250319004\n",
      "Class 511: 0.0021425026934593916\n",
      "Class 512: 0.001648079021833837\n",
      "Class 513: 0.0030607180669903755\n",
      "Class 514: 0.0026781284250319004\n",
      "Class 515: 0.0021425026934593916\n",
      "Class 516: 0.003570837900042534\n",
      "Class 517: 0.0010202393168583512\n",
      "Class 518: 0.004285005386918783\n",
      "Class 519: 0.004285005386918783\n",
      "Class 520: 0.0026781284250319004\n",
      "Class 521: 0.003570837900042534\n",
      "Class 522: 0.0021425026934593916\n",
      "Class 523: 0.0026781284250319004\n",
      "Class 524: 0.004285005386918783\n",
      "Class 525: 0.003570837900042534\n",
      "Class 526: 0.0019477297319099307\n",
      "Class 527: 0.0021425026934593916\n",
      "Class 528: 0.0030607180669903755\n",
      "Class 529: 0.004285005386918783\n",
      "Class 530: 0.0030607180669903755\n",
      "Class 531: 0.004285005386918783\n",
      "Class 532: 0.0015303590334951878\n",
      "Class 533: 0.0030607180669903755\n",
      "Class 534: 0.0026781284250319004\n",
      "Class 535: 0.0030607180669903755\n",
      "Class 536: 0.003570837900042534\n",
      "Class 537: 0.003570837900042534\n",
      "Class 538: 0.004285005386918783\n",
      "Class 539: 0.003570837900042534\n",
      "Class 540: 0.0030607180669903755\n",
      "Class 541: 0.0023805585224181414\n",
      "Class 542: 0.004285005386918783\n",
      "Class 543: 0.0021425026934593916\n",
      "Class 544: 0.0030607180669903755\n",
      "Class 545: 0.004285005386918783\n",
      "Class 546: 0.0030607180669903755\n",
      "Class 547: 0.004285005386918783\n",
      "Class 548: 0.004285005386918783\n",
      "Class 549: 0.0030607180669903755\n",
      "Class 550: 0.0030607180669903755\n",
      "Class 551: 0.003570837900042534\n",
      "Class 552: 0.0030607180669903755\n",
      "Class 553: 0.000184698510565795\n",
      "Class 554: 0.00017706633661873639\n",
      "Class 555: 0.0001714002137305215\n",
      "Class 556: 0.00018793882918544114\n",
      "Class 557: 0.000151950545841828\n",
      "Class 558: 0.00019655987853184342\n",
      "Class 559: 0.00016109042917378247\n",
      "Class 560: 0.00019301826250739396\n",
      "Class 561: 0.00019301826250739396\n",
      "Class 562: 0.00021425026352517307\n",
      "Class 563: 0.00018156802980229259\n",
      "Class 564: 0.00019655987853184342\n",
      "Class 565: 0.00018156802980229259\n",
      "Class 566: 0.00019655987853184342\n",
      "Class 567: 0.0001831198896979913\n",
      "Class 568: 0.00015870390052441508\n",
      "Class 569: 0.0001831198896979913\n",
      "Class 570: 0.00018156802980229259\n",
      "Class 571: 0.00018960201123263687\n",
      "Class 572: 0.00016480790509376675\n",
      "Class 573: 0.00019129487918689847\n",
      "Class 574: 0.00018793882918544114\n",
      "Class 575: 9.117032459471375e-05\n",
      "Class 576: 0.00017854188627097756\n",
      "Class 577: 0.0001714002137305215\n",
      "Class 578: 0.00018793882918544114\n",
      "Class 579: 0.0001831198896979913\n",
      "Class 580: 0.00018960201123263687\n",
      "Class 581: 0.0001863045763457194\n",
      "Class 582: 0.00014283350901678205\n",
      "Class 583: 0.00017854188627097756\n",
      "Class 584: 0.00016870099352672696\n",
      "Class 585: 0.00018156802980229259\n",
      "Class 586: 0.00017706633661873639\n",
      "Class 587: 0.00017854188627097756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 18:54:54.791302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:54.825502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:54.825568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:54.827232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:54.827301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:54.827344: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:55.043253: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:55.043336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:55.043347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-23 18:54:55.043399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-23 18:54:55.043417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2255 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_csv_file = \"/home/halwa/fyp/Training/train2.csv\" # Replace with the actual path to your training dataset CSV file\n",
    "\n",
    "# Read the CSV file\n",
    "train_df = pd.read_csv(train_csv_file, encoding='ISO-8859-1')\n",
    "\n",
    "# Extract class names and convert them to indices\n",
    "class_names = train_df['Species'].unique()\n",
    "class_indices = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Convert class names to indices in the DataFrame\n",
    "train_df['Class Index'] = train_df['Species'].map(class_indices)\n",
    "\n",
    "# Calculate class weights based on class frequencies\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(train_df['Class Index']), y=train_df['Class Index'])\n",
    "\n",
    "# Normalize class weights to sum to 1\n",
    "class_weights /= np.sum(class_weights)\n",
    "\n",
    "# Create the alpha tensor\n",
    "alpha_tensor = tf.constant(class_weights, dtype=tf.float32)\n",
    "\n",
    "# Convert alpha tensor to a NumPy array\n",
    "alpha_array = alpha_tensor.numpy()\n",
    "\n",
    "# Print alpha values\n",
    "print(\"Alpha values:\")\n",
    "for class_idx, alpha in enumerate(alpha_array):\n",
    "    print(f\"Class {class_idx}: {alpha}\")\n",
    "\n",
    "# Use alpha_array with CategoricalFocalCrossentropy\n",
    "categorical_focal_loss = tf.keras.losses.CategoricalFocalCrossentropy(alpha=alpha_array, gamma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping to monitor the validation loss and avoid overfitting\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "#reducing learning rate on plateau\n",
    "rlrop = ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience= 5, factor= 0.5, min_lr= 1e-6, verbose=1)\n",
    "\n",
    "#clr\n",
    "lr_schedule = tfa.optimizers.TriangularCyclicalLearningRate(\n",
    "    initial_learning_rate=1e-3,\n",
    "    maximal_learning_rate=1e-2,\n",
    "    step_size=1504,\n",
    "    scale_mode=\"cycle\",\n",
    "    name=\"CyclicScheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(240,240,3), pooling=None, include_preprocessing=False)\n",
    "model.trainable=False\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "top_dropout_rate = 0.2\n",
    "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "outputs = layers.Dense(588, activation=\"softmax\", name=\"pred\")(x)\n",
    "model = keras.Model(model.inputs, outputs, name=\"EfficientNet\")\n",
    "for layer in model.layers[:-1]: #freezing our low level layer weights\n",
    "  layer.trainable = False\n",
    "max_lr = 1e-2 # Adjust as needed\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "sgd = SGD(learning_rate=max_lr, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss=categorical_focal_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, input_2 : False\n",
      "1, stem_conv : False\n",
      "2, stem_bn : False\n",
      "3, stem_activation : False\n",
      "4, block1a_project_conv : False\n",
      "5, block1a_project_bn : False\n",
      "6, block1a_project_activation : False\n",
      "7, block1a_add : False\n",
      "8, block1b_project_conv : False\n",
      "9, block1b_project_bn : False\n",
      "10, block1b_project_activation : False\n",
      "11, block1b_drop : False\n",
      "12, block1b_add : False\n",
      "13, block2a_expand_conv : False\n",
      "14, block2a_expand_bn : False\n",
      "15, block2a_expand_activation : False\n",
      "16, block2a_project_conv : False\n",
      "17, block2a_project_bn : False\n",
      "18, block2b_expand_conv : False\n",
      "19, block2b_expand_bn : False\n",
      "20, block2b_expand_activation : False\n",
      "21, block2b_project_conv : False\n",
      "22, block2b_project_bn : False\n",
      "23, block2b_drop : False\n",
      "24, block2b_add : False\n",
      "25, block2c_expand_conv : False\n",
      "26, block2c_expand_bn : False\n",
      "27, block2c_expand_activation : False\n",
      "28, block2c_project_conv : False\n",
      "29, block2c_project_bn : False\n",
      "30, block2c_drop : False\n",
      "31, block2c_add : False\n",
      "32, block2d_expand_conv : False\n",
      "33, block2d_expand_bn : False\n",
      "34, block2d_expand_activation : False\n",
      "35, block2d_project_conv : False\n",
      "36, block2d_project_bn : False\n",
      "37, block2d_drop : False\n",
      "38, block2d_add : False\n",
      "39, block3a_expand_conv : False\n",
      "40, block3a_expand_bn : False\n",
      "41, block3a_expand_activation : False\n",
      "42, block3a_project_conv : False\n",
      "43, block3a_project_bn : False\n",
      "44, block3b_expand_conv : False\n",
      "45, block3b_expand_bn : False\n",
      "46, block3b_expand_activation : False\n",
      "47, block3b_project_conv : False\n",
      "48, block3b_project_bn : False\n",
      "49, block3b_drop : False\n",
      "50, block3b_add : False\n",
      "51, block3c_expand_conv : False\n",
      "52, block3c_expand_bn : False\n",
      "53, block3c_expand_activation : False\n",
      "54, block3c_project_conv : False\n",
      "55, block3c_project_bn : False\n",
      "56, block3c_drop : False\n",
      "57, block3c_add : False\n",
      "58, block3d_expand_conv : False\n",
      "59, block3d_expand_bn : False\n",
      "60, block3d_expand_activation : False\n",
      "61, block3d_project_conv : False\n",
      "62, block3d_project_bn : False\n",
      "63, block3d_drop : False\n",
      "64, block3d_add : False\n",
      "65, block4a_expand_conv : False\n",
      "66, block4a_expand_bn : False\n",
      "67, block4a_expand_activation : False\n",
      "68, block4a_dwconv2 : False\n",
      "69, block4a_bn : False\n",
      "70, block4a_activation : False\n",
      "71, block4a_se_squeeze : False\n",
      "72, block4a_se_reshape : False\n",
      "73, block4a_se_reduce : False\n",
      "74, block4a_se_expand : False\n",
      "75, block4a_se_excite : False\n",
      "76, block4a_project_conv : False\n",
      "77, block4a_project_bn : False\n",
      "78, block4b_expand_conv : False\n",
      "79, block4b_expand_bn : False\n",
      "80, block4b_expand_activation : False\n",
      "81, block4b_dwconv2 : False\n",
      "82, block4b_bn : False\n",
      "83, block4b_activation : False\n",
      "84, block4b_se_squeeze : False\n",
      "85, block4b_se_reshape : False\n",
      "86, block4b_se_reduce : False\n",
      "87, block4b_se_expand : False\n",
      "88, block4b_se_excite : False\n",
      "89, block4b_project_conv : False\n",
      "90, block4b_project_bn : False\n",
      "91, block4b_drop : False\n",
      "92, block4b_add : False\n",
      "93, block4c_expand_conv : False\n",
      "94, block4c_expand_bn : False\n",
      "95, block4c_expand_activation : False\n",
      "96, block4c_dwconv2 : False\n",
      "97, block4c_bn : False\n",
      "98, block4c_activation : False\n",
      "99, block4c_se_squeeze : False\n",
      "100, block4c_se_reshape : False\n",
      "101, block4c_se_reduce : False\n",
      "102, block4c_se_expand : False\n",
      "103, block4c_se_excite : False\n",
      "104, block4c_project_conv : False\n",
      "105, block4c_project_bn : False\n",
      "106, block4c_drop : False\n",
      "107, block4c_add : False\n",
      "108, block4d_expand_conv : False\n",
      "109, block4d_expand_bn : False\n",
      "110, block4d_expand_activation : False\n",
      "111, block4d_dwconv2 : False\n",
      "112, block4d_bn : False\n",
      "113, block4d_activation : False\n",
      "114, block4d_se_squeeze : False\n",
      "115, block4d_se_reshape : False\n",
      "116, block4d_se_reduce : False\n",
      "117, block4d_se_expand : False\n",
      "118, block4d_se_excite : False\n",
      "119, block4d_project_conv : False\n",
      "120, block4d_project_bn : False\n",
      "121, block4d_drop : False\n",
      "122, block4d_add : False\n",
      "123, block4e_expand_conv : False\n",
      "124, block4e_expand_bn : False\n",
      "125, block4e_expand_activation : False\n",
      "126, block4e_dwconv2 : False\n",
      "127, block4e_bn : False\n",
      "128, block4e_activation : False\n",
      "129, block4e_se_squeeze : False\n",
      "130, block4e_se_reshape : False\n",
      "131, block4e_se_reduce : False\n",
      "132, block4e_se_expand : False\n",
      "133, block4e_se_excite : False\n",
      "134, block4e_project_conv : False\n",
      "135, block4e_project_bn : False\n",
      "136, block4e_drop : False\n",
      "137, block4e_add : False\n",
      "138, block4f_expand_conv : False\n",
      "139, block4f_expand_bn : False\n",
      "140, block4f_expand_activation : False\n",
      "141, block4f_dwconv2 : False\n",
      "142, block4f_bn : False\n",
      "143, block4f_activation : False\n",
      "144, block4f_se_squeeze : False\n",
      "145, block4f_se_reshape : False\n",
      "146, block4f_se_reduce : False\n",
      "147, block4f_se_expand : False\n",
      "148, block4f_se_excite : False\n",
      "149, block4f_project_conv : False\n",
      "150, block4f_project_bn : False\n",
      "151, block4f_drop : False\n",
      "152, block4f_add : False\n",
      "153, block5a_expand_conv : False\n",
      "154, block5a_expand_bn : False\n",
      "155, block5a_expand_activation : False\n",
      "156, block5a_dwconv2 : False\n",
      "157, block5a_bn : False\n",
      "158, block5a_activation : False\n",
      "159, block5a_se_squeeze : False\n",
      "160, block5a_se_reshape : False\n",
      "161, block5a_se_reduce : False\n",
      "162, block5a_se_expand : False\n",
      "163, block5a_se_excite : False\n",
      "164, block5a_project_conv : False\n",
      "165, block5a_project_bn : False\n",
      "166, block5b_expand_conv : False\n",
      "167, block5b_expand_bn : False\n",
      "168, block5b_expand_activation : False\n",
      "169, block5b_dwconv2 : False\n",
      "170, block5b_bn : False\n",
      "171, block5b_activation : False\n",
      "172, block5b_se_squeeze : False\n",
      "173, block5b_se_reshape : False\n",
      "174, block5b_se_reduce : False\n",
      "175, block5b_se_expand : False\n",
      "176, block5b_se_excite : False\n",
      "177, block5b_project_conv : False\n",
      "178, block5b_project_bn : False\n",
      "179, block5b_drop : False\n",
      "180, block5b_add : False\n",
      "181, block5c_expand_conv : False\n",
      "182, block5c_expand_bn : False\n",
      "183, block5c_expand_activation : False\n",
      "184, block5c_dwconv2 : False\n",
      "185, block5c_bn : False\n",
      "186, block5c_activation : False\n",
      "187, block5c_se_squeeze : False\n",
      "188, block5c_se_reshape : False\n",
      "189, block5c_se_reduce : False\n",
      "190, block5c_se_expand : False\n",
      "191, block5c_se_excite : False\n",
      "192, block5c_project_conv : False\n",
      "193, block5c_project_bn : False\n",
      "194, block5c_drop : False\n",
      "195, block5c_add : False\n",
      "196, block5d_expand_conv : False\n",
      "197, block5d_expand_bn : False\n",
      "198, block5d_expand_activation : False\n",
      "199, block5d_dwconv2 : False\n",
      "200, block5d_bn : False\n",
      "201, block5d_activation : False\n",
      "202, block5d_se_squeeze : False\n",
      "203, block5d_se_reshape : False\n",
      "204, block5d_se_reduce : False\n",
      "205, block5d_se_expand : False\n",
      "206, block5d_se_excite : False\n",
      "207, block5d_project_conv : False\n",
      "208, block5d_project_bn : False\n",
      "209, block5d_drop : False\n",
      "210, block5d_add : False\n",
      "211, block5e_expand_conv : False\n",
      "212, block5e_expand_bn : False\n",
      "213, block5e_expand_activation : False\n",
      "214, block5e_dwconv2 : False\n",
      "215, block5e_bn : False\n",
      "216, block5e_activation : False\n",
      "217, block5e_se_squeeze : False\n",
      "218, block5e_se_reshape : False\n",
      "219, block5e_se_reduce : False\n",
      "220, block5e_se_expand : False\n",
      "221, block5e_se_excite : False\n",
      "222, block5e_project_conv : False\n",
      "223, block5e_project_bn : False\n",
      "224, block5e_drop : False\n",
      "225, block5e_add : False\n",
      "226, block5f_expand_conv : False\n",
      "227, block5f_expand_bn : False\n",
      "228, block5f_expand_activation : False\n",
      "229, block5f_dwconv2 : False\n",
      "230, block5f_bn : False\n",
      "231, block5f_activation : False\n",
      "232, block5f_se_squeeze : False\n",
      "233, block5f_se_reshape : False\n",
      "234, block5f_se_reduce : False\n",
      "235, block5f_se_expand : False\n",
      "236, block5f_se_excite : False\n",
      "237, block5f_project_conv : False\n",
      "238, block5f_project_bn : False\n",
      "239, block5f_drop : False\n",
      "240, block5f_add : False\n",
      "241, block5g_expand_conv : False\n",
      "242, block5g_expand_bn : False\n",
      "243, block5g_expand_activation : False\n",
      "244, block5g_dwconv2 : False\n",
      "245, block5g_bn : False\n",
      "246, block5g_activation : False\n",
      "247, block5g_se_squeeze : False\n",
      "248, block5g_se_reshape : False\n",
      "249, block5g_se_reduce : False\n",
      "250, block5g_se_expand : False\n",
      "251, block5g_se_excite : False\n",
      "252, block5g_project_conv : False\n",
      "253, block5g_project_bn : False\n",
      "254, block5g_drop : False\n",
      "255, block5g_add : False\n",
      "256, block5h_expand_conv : False\n",
      "257, block5h_expand_bn : False\n",
      "258, block5h_expand_activation : False\n",
      "259, block5h_dwconv2 : False\n",
      "260, block5h_bn : False\n",
      "261, block5h_activation : False\n",
      "262, block5h_se_squeeze : False\n",
      "263, block5h_se_reshape : False\n",
      "264, block5h_se_reduce : False\n",
      "265, block5h_se_expand : False\n",
      "266, block5h_se_excite : False\n",
      "267, block5h_project_conv : False\n",
      "268, block5h_project_bn : False\n",
      "269, block5h_drop : False\n",
      "270, block5h_add : False\n",
      "271, block5i_expand_conv : False\n",
      "272, block5i_expand_bn : False\n",
      "273, block5i_expand_activation : False\n",
      "274, block5i_dwconv2 : False\n",
      "275, block5i_bn : False\n",
      "276, block5i_activation : False\n",
      "277, block5i_se_squeeze : False\n",
      "278, block5i_se_reshape : False\n",
      "279, block5i_se_reduce : False\n",
      "280, block5i_se_expand : False\n",
      "281, block5i_se_excite : False\n",
      "282, block5i_project_conv : False\n",
      "283, block5i_project_bn : False\n",
      "284, block5i_drop : False\n",
      "285, block5i_add : False\n",
      "286, block6a_expand_conv : False\n",
      "287, block6a_expand_bn : False\n",
      "288, block6a_expand_activation : False\n",
      "289, block6a_dwconv2 : False\n",
      "290, block6a_bn : False\n",
      "291, block6a_activation : False\n",
      "292, block6a_se_squeeze : False\n",
      "293, block6a_se_reshape : False\n",
      "294, block6a_se_reduce : False\n",
      "295, block6a_se_expand : False\n",
      "296, block6a_se_excite : False\n",
      "297, block6a_project_conv : False\n",
      "298, block6a_project_bn : False\n",
      "299, block6b_expand_conv : False\n",
      "300, block6b_expand_bn : False\n",
      "301, block6b_expand_activation : False\n",
      "302, block6b_dwconv2 : False\n",
      "303, block6b_bn : False\n",
      "304, block6b_activation : False\n",
      "305, block6b_se_squeeze : False\n",
      "306, block6b_se_reshape : False\n",
      "307, block6b_se_reduce : False\n",
      "308, block6b_se_expand : False\n",
      "309, block6b_se_excite : False\n",
      "310, block6b_project_conv : False\n",
      "311, block6b_project_bn : False\n",
      "312, block6b_drop : False\n",
      "313, block6b_add : False\n",
      "314, block6c_expand_conv : False\n",
      "315, block6c_expand_bn : False\n",
      "316, block6c_expand_activation : False\n",
      "317, block6c_dwconv2 : False\n",
      "318, block6c_bn : False\n",
      "319, block6c_activation : False\n",
      "320, block6c_se_squeeze : False\n",
      "321, block6c_se_reshape : False\n",
      "322, block6c_se_reduce : False\n",
      "323, block6c_se_expand : False\n",
      "324, block6c_se_excite : False\n",
      "325, block6c_project_conv : False\n",
      "326, block6c_project_bn : False\n",
      "327, block6c_drop : False\n",
      "328, block6c_add : False\n",
      "329, block6d_expand_conv : False\n",
      "330, block6d_expand_bn : False\n",
      "331, block6d_expand_activation : False\n",
      "332, block6d_dwconv2 : False\n",
      "333, block6d_bn : False\n",
      "334, block6d_activation : False\n",
      "335, block6d_se_squeeze : False\n",
      "336, block6d_se_reshape : False\n",
      "337, block6d_se_reduce : False\n",
      "338, block6d_se_expand : False\n",
      "339, block6d_se_excite : False\n",
      "340, block6d_project_conv : False\n",
      "341, block6d_project_bn : False\n",
      "342, block6d_drop : False\n",
      "343, block6d_add : False\n",
      "344, block6e_expand_conv : False\n",
      "345, block6e_expand_bn : False\n",
      "346, block6e_expand_activation : False\n",
      "347, block6e_dwconv2 : False\n",
      "348, block6e_bn : False\n",
      "349, block6e_activation : False\n",
      "350, block6e_se_squeeze : False\n",
      "351, block6e_se_reshape : False\n",
      "352, block6e_se_reduce : False\n",
      "353, block6e_se_expand : False\n",
      "354, block6e_se_excite : False\n",
      "355, block6e_project_conv : False\n",
      "356, block6e_project_bn : False\n",
      "357, block6e_drop : False\n",
      "358, block6e_add : False\n",
      "359, block6f_expand_conv : False\n",
      "360, block6f_expand_bn : False\n",
      "361, block6f_expand_activation : False\n",
      "362, block6f_dwconv2 : False\n",
      "363, block6f_bn : False\n",
      "364, block6f_activation : False\n",
      "365, block6f_se_squeeze : False\n",
      "366, block6f_se_reshape : False\n",
      "367, block6f_se_reduce : False\n",
      "368, block6f_se_expand : False\n",
      "369, block6f_se_excite : False\n",
      "370, block6f_project_conv : False\n",
      "371, block6f_project_bn : False\n",
      "372, block6f_drop : False\n",
      "373, block6f_add : False\n",
      "374, block6g_expand_conv : False\n",
      "375, block6g_expand_bn : False\n",
      "376, block6g_expand_activation : False\n",
      "377, block6g_dwconv2 : False\n",
      "378, block6g_bn : False\n",
      "379, block6g_activation : False\n",
      "380, block6g_se_squeeze : False\n",
      "381, block6g_se_reshape : False\n",
      "382, block6g_se_reduce : False\n",
      "383, block6g_se_expand : False\n",
      "384, block6g_se_excite : False\n",
      "385, block6g_project_conv : False\n",
      "386, block6g_project_bn : False\n",
      "387, block6g_drop : False\n",
      "388, block6g_add : False\n",
      "389, block6h_expand_conv : False\n",
      "390, block6h_expand_bn : False\n",
      "391, block6h_expand_activation : False\n",
      "392, block6h_dwconv2 : False\n",
      "393, block6h_bn : False\n",
      "394, block6h_activation : False\n",
      "395, block6h_se_squeeze : False\n",
      "396, block6h_se_reshape : False\n",
      "397, block6h_se_reduce : False\n",
      "398, block6h_se_expand : False\n",
      "399, block6h_se_excite : False\n",
      "400, block6h_project_conv : False\n",
      "401, block6h_project_bn : False\n",
      "402, block6h_drop : False\n",
      "403, block6h_add : False\n",
      "404, block6i_expand_conv : False\n",
      "405, block6i_expand_bn : False\n",
      "406, block6i_expand_activation : False\n",
      "407, block6i_dwconv2 : False\n",
      "408, block6i_bn : False\n",
      "409, block6i_activation : False\n",
      "410, block6i_se_squeeze : False\n",
      "411, block6i_se_reshape : False\n",
      "412, block6i_se_reduce : False\n",
      "413, block6i_se_expand : False\n",
      "414, block6i_se_excite : False\n",
      "415, block6i_project_conv : False\n",
      "416, block6i_project_bn : False\n",
      "417, block6i_drop : False\n",
      "418, block6i_add : False\n",
      "419, block6j_expand_conv : False\n",
      "420, block6j_expand_bn : False\n",
      "421, block6j_expand_activation : False\n",
      "422, block6j_dwconv2 : False\n",
      "423, block6j_bn : False\n",
      "424, block6j_activation : False\n",
      "425, block6j_se_squeeze : False\n",
      "426, block6j_se_reshape : False\n",
      "427, block6j_se_reduce : False\n",
      "428, block6j_se_expand : False\n",
      "429, block6j_se_excite : False\n",
      "430, block6j_project_conv : False\n",
      "431, block6j_project_bn : False\n",
      "432, block6j_drop : False\n",
      "433, block6j_add : False\n",
      "434, block6k_expand_conv : False\n",
      "435, block6k_expand_bn : False\n",
      "436, block6k_expand_activation : False\n",
      "437, block6k_dwconv2 : False\n",
      "438, block6k_bn : False\n",
      "439, block6k_activation : False\n",
      "440, block6k_se_squeeze : False\n",
      "441, block6k_se_reshape : False\n",
      "442, block6k_se_reduce : False\n",
      "443, block6k_se_expand : False\n",
      "444, block6k_se_excite : False\n",
      "445, block6k_project_conv : False\n",
      "446, block6k_project_bn : False\n",
      "447, block6k_drop : False\n",
      "448, block6k_add : False\n",
      "449, block6l_expand_conv : False\n",
      "450, block6l_expand_bn : False\n",
      "451, block6l_expand_activation : False\n",
      "452, block6l_dwconv2 : False\n",
      "453, block6l_bn : False\n",
      "454, block6l_activation : False\n",
      "455, block6l_se_squeeze : False\n",
      "456, block6l_se_reshape : False\n",
      "457, block6l_se_reduce : False\n",
      "458, block6l_se_expand : False\n",
      "459, block6l_se_excite : False\n",
      "460, block6l_project_conv : False\n",
      "461, block6l_project_bn : False\n",
      "462, block6l_drop : False\n",
      "463, block6l_add : False\n",
      "464, block6m_expand_conv : False\n",
      "465, block6m_expand_bn : False\n",
      "466, block6m_expand_activation : False\n",
      "467, block6m_dwconv2 : False\n",
      "468, block6m_bn : False\n",
      "469, block6m_activation : False\n",
      "470, block6m_se_squeeze : False\n",
      "471, block6m_se_reshape : False\n",
      "472, block6m_se_reduce : False\n",
      "473, block6m_se_expand : False\n",
      "474, block6m_se_excite : False\n",
      "475, block6m_project_conv : False\n",
      "476, block6m_project_bn : False\n",
      "477, block6m_drop : False\n",
      "478, block6m_add : False\n",
      "479, block6n_expand_conv : False\n",
      "480, block6n_expand_bn : False\n",
      "481, block6n_expand_activation : False\n",
      "482, block6n_dwconv2 : False\n",
      "483, block6n_bn : False\n",
      "484, block6n_activation : False\n",
      "485, block6n_se_squeeze : False\n",
      "486, block6n_se_reshape : False\n",
      "487, block6n_se_reduce : False\n",
      "488, block6n_se_expand : False\n",
      "489, block6n_se_excite : False\n",
      "490, block6n_project_conv : False\n",
      "491, block6n_project_bn : False\n",
      "492, block6n_drop : False\n",
      "493, block6n_add : False\n",
      "494, block6o_expand_conv : False\n",
      "495, block6o_expand_bn : False\n",
      "496, block6o_expand_activation : False\n",
      "497, block6o_dwconv2 : False\n",
      "498, block6o_bn : False\n",
      "499, block6o_activation : False\n",
      "500, block6o_se_squeeze : False\n",
      "501, block6o_se_reshape : False\n",
      "502, block6o_se_reduce : False\n",
      "503, block6o_se_expand : False\n",
      "504, block6o_se_excite : False\n",
      "505, block6o_project_conv : False\n",
      "506, block6o_project_bn : False\n",
      "507, block6o_drop : False\n",
      "508, block6o_add : False\n",
      "509, top_conv : False\n",
      "510, top_bn : False\n",
      "511, top_activation : False\n",
      "512, avg_pool : False\n",
      "513, top_dropout : False\n",
      "514, pred : True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "  print(f\"{i}, {layer.name} : {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path for saving model checkpoints\n",
    "checkpoint_filepath = \"/home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\" #edit this path\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, save_best_only=True, verbose=1, monitor='val_accuracy', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.4199\n",
      "Epoch 1: val_accuracy improved from -inf to 0.43873, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 536s 712ms/step - loss: 0.0038 - accuracy: 0.4199 - val_loss: 0.0046 - val_accuracy: 0.4387\n",
      "Epoch 2/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.4648\n",
      "Epoch 2: val_accuracy improved from 0.43873 to 0.55151, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 544s 723ms/step - loss: 0.0040 - accuracy: 0.4648 - val_loss: 0.0037 - val_accuracy: 0.5515\n",
      "Epoch 3/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.5833\n",
      "Epoch 3: val_accuracy improved from 0.55151 to 0.62783, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 551s 732ms/step - loss: 0.0023 - accuracy: 0.5833 - val_loss: 0.0026 - val_accuracy: 0.6278\n",
      "Epoch 4/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.6115\n",
      "Epoch 4: val_accuracy did not improve from 0.62783\n",
      "752/752 [==============================] - 490s 651ms/step - loss: 0.0019 - accuracy: 0.6115 - val_loss: 0.0030 - val_accuracy: 0.5967\n",
      "Epoch 5/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.5320\n",
      "Epoch 5: val_accuracy did not improve from 0.62783\n",
      "752/752 [==============================] - 501s 665ms/step - loss: 0.0032 - accuracy: 0.5320 - val_loss: 0.0047 - val_accuracy: 0.5087\n",
      "Epoch 6/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.5252\n",
      "Epoch 6: val_accuracy did not improve from 0.62783\n",
      "752/752 [==============================] - 494s 657ms/step - loss: 0.0036 - accuracy: 0.5252 - val_loss: 0.0038 - val_accuracy: 0.5871\n",
      "Epoch 7/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.6195\n",
      "Epoch 7: val_accuracy improved from 0.62783 to 0.65012, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 545s 724ms/step - loss: 0.0023 - accuracy: 0.6195 - val_loss: 0.0029 - val_accuracy: 0.6501\n",
      "Epoch 8/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.6547\n",
      "Epoch 8: val_accuracy did not improve from 0.65012\n",
      "752/752 [==============================] - 493s 656ms/step - loss: 0.0019 - accuracy: 0.6547 - val_loss: 0.0031 - val_accuracy: 0.6283\n",
      "Epoch 9/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.5753\n",
      "Epoch 9: val_accuracy did not improve from 0.65012\n",
      "752/752 [==============================] - 496s 659ms/step - loss: 0.0030 - accuracy: 0.5753 - val_loss: 0.0046 - val_accuracy: 0.5510\n",
      "Epoch 10/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.5681\n",
      "Epoch 10: val_accuracy did not improve from 0.65012\n",
      "752/752 [==============================] - 495s 658ms/step - loss: 0.0034 - accuracy: 0.5681 - val_loss: 0.0039 - val_accuracy: 0.6111\n",
      "Epoch 11/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.6465\n",
      "Epoch 11: val_accuracy improved from 0.65012 to 0.65777, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 545s 724ms/step - loss: 0.0023 - accuracy: 0.6465 - val_loss: 0.0032 - val_accuracy: 0.6578\n",
      "Epoch 12/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.6725\n",
      "Epoch 12: val_accuracy did not improve from 0.65777\n",
      "752/752 [==============================] - 499s 664ms/step - loss: 0.0020 - accuracy: 0.6725 - val_loss: 0.0034 - val_accuracy: 0.6522\n",
      "Epoch 13/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.6080\n",
      "Epoch 13: val_accuracy did not improve from 0.65777\n",
      "752/752 [==============================] - 505s 671ms/step - loss: 0.0029 - accuracy: 0.6080 - val_loss: 0.0045 - val_accuracy: 0.5670\n",
      "Epoch 14/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.5839\n",
      "Epoch 14: val_accuracy did not improve from 0.65777\n",
      "752/752 [==============================] - 495s 658ms/step - loss: 0.0034 - accuracy: 0.5839 - val_loss: 0.0040 - val_accuracy: 0.6342\n",
      "Epoch 15/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.6623\n",
      "Epoch 15: val_accuracy improved from 0.65777 to 0.67258, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 553s 736ms/step - loss: 0.0023 - accuracy: 0.6623 - val_loss: 0.0034 - val_accuracy: 0.6726\n",
      "Epoch 16/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.6852\n",
      "Epoch 16: val_accuracy did not improve from 0.67258\n",
      "752/752 [==============================] - 500s 665ms/step - loss: 0.0019 - accuracy: 0.6852 - val_loss: 0.0036 - val_accuracy: 0.6531\n",
      "Epoch 17/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.6192\n",
      "Epoch 17: val_accuracy did not improve from 0.67258\n",
      "752/752 [==============================] - 496s 659ms/step - loss: 0.0030 - accuracy: 0.6192 - val_loss: 0.0047 - val_accuracy: 0.5992\n",
      "Epoch 18/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.6129\n",
      "Epoch 18: val_accuracy did not improve from 0.67258\n",
      "752/752 [==============================] - 496s 660ms/step - loss: 0.0032 - accuracy: 0.6129 - val_loss: 0.0039 - val_accuracy: 0.6470\n",
      "Epoch 19/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.6780\n",
      "Epoch 19: val_accuracy improved from 0.67258 to 0.68788, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 548s 729ms/step - loss: 0.0022 - accuracy: 0.6780 - val_loss: 0.0035 - val_accuracy: 0.6879\n",
      "Epoch 20/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.7052\n",
      "Epoch 20: val_accuracy did not improve from 0.68788\n",
      "752/752 [==============================] - 506s 673ms/step - loss: 0.0019 - accuracy: 0.7052 - val_loss: 0.0038 - val_accuracy: 0.6612\n",
      "Epoch 21/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.6439\n",
      "Epoch 21: val_accuracy did not improve from 0.68788\n",
      "752/752 [==============================] - 499s 663ms/step - loss: 0.0028 - accuracy: 0.6439 - val_loss: 0.0047 - val_accuracy: 0.6187\n",
      "Epoch 22/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.6235\n",
      "Epoch 22: val_accuracy did not improve from 0.68788\n",
      "752/752 [==============================] - 494s 656ms/step - loss: 0.0033 - accuracy: 0.6235 - val_loss: 0.0042 - val_accuracy: 0.6503\n",
      "Epoch 23/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.6839\n",
      "Epoch 23: val_accuracy improved from 0.68788 to 0.68918, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 538s 715ms/step - loss: 0.0023 - accuracy: 0.6839 - val_loss: 0.0036 - val_accuracy: 0.6892\n",
      "Epoch 24/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7064\n",
      "Epoch 24: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 494s 657ms/step - loss: 0.0020 - accuracy: 0.7064 - val_loss: 0.0038 - val_accuracy: 0.6706\n",
      "Epoch 25/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.6576\n",
      "Epoch 25: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 498s 662ms/step - loss: 0.0027 - accuracy: 0.6576 - val_loss: 0.0047 - val_accuracy: 0.6093\n",
      "Epoch 26/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.6343\n",
      "Epoch 26: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 493s 655ms/step - loss: 0.0033 - accuracy: 0.6343 - val_loss: 0.0043 - val_accuracy: 0.6461\n",
      "Epoch 27/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.6951\n",
      "Epoch 27: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 508s 675ms/step - loss: 0.0023 - accuracy: 0.6951 - val_loss: 0.0038 - val_accuracy: 0.6840\n",
      "Epoch 28/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7194\n",
      "Epoch 28: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 533s 709ms/step - loss: 0.0020 - accuracy: 0.7194 - val_loss: 0.0039 - val_accuracy: 0.6732\n",
      "Epoch 29/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.6681\n",
      "Epoch 29: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 510s 678ms/step - loss: 0.0027 - accuracy: 0.6681 - val_loss: 0.0049 - val_accuracy: 0.6255\n",
      "Epoch 30/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.6465\n",
      "Epoch 30: val_accuracy did not improve from 0.68918\n",
      "752/752 [==============================] - 497s 660ms/step - loss: 0.0031 - accuracy: 0.6465 - val_loss: 0.0042 - val_accuracy: 0.6649\n",
      "Epoch 31/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.7041\n",
      "Epoch 31: val_accuracy improved from 0.68918 to 0.70285, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 541s 719ms/step - loss: 0.0023 - accuracy: 0.7041 - val_loss: 0.0037 - val_accuracy: 0.7028\n",
      "Epoch 32/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7230\n",
      "Epoch 32: val_accuracy did not improve from 0.70285\n",
      "752/752 [==============================] - 488s 649ms/step - loss: 0.0020 - accuracy: 0.7230 - val_loss: 0.0040 - val_accuracy: 0.6749\n",
      "Epoch 33/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.6755\n",
      "Epoch 33: val_accuracy did not improve from 0.70285\n",
      "752/752 [==============================] - 500s 665ms/step - loss: 0.0027 - accuracy: 0.6755 - val_loss: 0.0050 - val_accuracy: 0.6251\n",
      "Epoch 34/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.6538\n",
      "Epoch 34: val_accuracy did not improve from 0.70285\n",
      "752/752 [==============================] - 489s 649ms/step - loss: 0.0031 - accuracy: 0.6538 - val_loss: 0.0044 - val_accuracy: 0.6602\n",
      "Epoch 35/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.7077\n",
      "Epoch 35: val_accuracy improved from 0.70285 to 0.70431, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 539s 717ms/step - loss: 0.0023 - accuracy: 0.7077 - val_loss: 0.0038 - val_accuracy: 0.7043\n",
      "Epoch 36/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7288\n",
      "Epoch 36: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 508s 676ms/step - loss: 0.0020 - accuracy: 0.7288 - val_loss: 0.0040 - val_accuracy: 0.6771\n",
      "Epoch 37/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.6742\n",
      "Epoch 37: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 487s 648ms/step - loss: 0.0027 - accuracy: 0.6742 - val_loss: 0.0046 - val_accuracy: 0.6410\n",
      "Epoch 38/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.6651\n",
      "Epoch 38: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 491s 652ms/step - loss: 0.0031 - accuracy: 0.6651 - val_loss: 0.0042 - val_accuracy: 0.6649\n",
      "Epoch 39/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.7180\n",
      "Epoch 39: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 480s 639ms/step - loss: 0.0023 - accuracy: 0.7180 - val_loss: 0.0038 - val_accuracy: 0.6962\n",
      "Epoch 40/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7304\n",
      "Epoch 40: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 473s 629ms/step - loss: 0.0020 - accuracy: 0.7304 - val_loss: 0.0040 - val_accuracy: 0.6871\n",
      "Epoch 41/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.6841\n",
      "Epoch 41: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 478s 635ms/step - loss: 0.0028 - accuracy: 0.6841 - val_loss: 0.0048 - val_accuracy: 0.6410\n",
      "Epoch 42/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.6710\n",
      "Epoch 42: val_accuracy did not improve from 0.70431\n",
      "752/752 [==============================] - 492s 654ms/step - loss: 0.0030 - accuracy: 0.6710 - val_loss: 0.0044 - val_accuracy: 0.6669\n",
      "Epoch 43/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.7192\n",
      "Epoch 43: val_accuracy improved from 0.70431 to 0.70561, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 519s 690ms/step - loss: 0.0022 - accuracy: 0.7192 - val_loss: 0.0039 - val_accuracy: 0.7056\n",
      "Epoch 44/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7363\n",
      "Epoch 44: val_accuracy did not improve from 0.70561\n",
      "752/752 [==============================] - 464s 617ms/step - loss: 0.0020 - accuracy: 0.7363 - val_loss: 0.0041 - val_accuracy: 0.6866\n",
      "Epoch 45/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.6990\n",
      "Epoch 45: val_accuracy did not improve from 0.70561\n",
      "752/752 [==============================] - 490s 651ms/step - loss: 0.0026 - accuracy: 0.6990 - val_loss: 0.0046 - val_accuracy: 0.6477\n",
      "Epoch 46/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.6820\n",
      "Epoch 46: val_accuracy did not improve from 0.70561\n",
      "752/752 [==============================] - 486s 646ms/step - loss: 0.0029 - accuracy: 0.6820 - val_loss: 0.0045 - val_accuracy: 0.6732\n",
      "Epoch 47/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.7297\n",
      "Epoch 47: val_accuracy improved from 0.70561 to 0.70708, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 530s 705ms/step - loss: 0.0022 - accuracy: 0.7297 - val_loss: 0.0040 - val_accuracy: 0.7071\n",
      "Epoch 48/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.7446\n",
      "Epoch 48: val_accuracy did not improve from 0.70708\n",
      "752/752 [==============================] - 468s 622ms/step - loss: 0.0020 - accuracy: 0.7446 - val_loss: 0.0043 - val_accuracy: 0.6972\n",
      "Epoch 49/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.7020\n",
      "Epoch 49: val_accuracy did not improve from 0.70708\n",
      "752/752 [==============================] - 475s 631ms/step - loss: 0.0027 - accuracy: 0.7020 - val_loss: 0.0048 - val_accuracy: 0.6636\n",
      "Epoch 50/50\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.6840\n",
      "Epoch 50: val_accuracy did not improve from 0.70708\n",
      "752/752 [==============================] - 470s 625ms/step - loss: 0.0030 - accuracy: 0.6840 - val_loss: 0.0043 - val_accuracy: 0.6817\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the image generator for training and validation\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=len(trainGen),\n",
    "    validation_data=valGen,\n",
    "    validation_steps=len(valGen),\n",
    "    callbacks=[model_checkpoint]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clr\n",
    "lr_schedule = tfa.optimizers.TriangularCyclicalLearningRate(\n",
    "    initial_learning_rate=1e-5,\n",
    "    maximal_learning_rate=1e-4,\n",
    "    step_size=6016,\n",
    "    scale_mode=\"cycle\",\n",
    "    name=\"CyclicScheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, input_2 : False\n",
      "1, stem_conv : False\n",
      "2, stem_bn : False\n",
      "3, stem_activation : False\n",
      "4, block1a_project_conv : False\n",
      "5, block1a_project_bn : False\n",
      "6, block1a_project_activation : False\n",
      "7, block1a_add : False\n",
      "8, block1b_project_conv : False\n",
      "9, block1b_project_bn : False\n",
      "10, block1b_project_activation : False\n",
      "11, block1b_drop : False\n",
      "12, block1b_add : False\n",
      "13, block2a_expand_conv : False\n",
      "14, block2a_expand_bn : False\n",
      "15, block2a_expand_activation : False\n",
      "16, block2a_project_conv : False\n",
      "17, block2a_project_bn : False\n",
      "18, block2b_expand_conv : False\n",
      "19, block2b_expand_bn : False\n",
      "20, block2b_expand_activation : False\n",
      "21, block2b_project_conv : False\n",
      "22, block2b_project_bn : False\n",
      "23, block2b_drop : False\n",
      "24, block2b_add : False\n",
      "25, block2c_expand_conv : False\n",
      "26, block2c_expand_bn : False\n",
      "27, block2c_expand_activation : False\n",
      "28, block2c_project_conv : False\n",
      "29, block2c_project_bn : False\n",
      "30, block2c_drop : False\n",
      "31, block2c_add : False\n",
      "32, block2d_expand_conv : False\n",
      "33, block2d_expand_bn : False\n",
      "34, block2d_expand_activation : False\n",
      "35, block2d_project_conv : False\n",
      "36, block2d_project_bn : False\n",
      "37, block2d_drop : False\n",
      "38, block2d_add : False\n",
      "39, block3a_expand_conv : False\n",
      "40, block3a_expand_bn : False\n",
      "41, block3a_expand_activation : False\n",
      "42, block3a_project_conv : False\n",
      "43, block3a_project_bn : False\n",
      "44, block3b_expand_conv : False\n",
      "45, block3b_expand_bn : False\n",
      "46, block3b_expand_activation : False\n",
      "47, block3b_project_conv : False\n",
      "48, block3b_project_bn : False\n",
      "49, block3b_drop : False\n",
      "50, block3b_add : False\n",
      "51, block3c_expand_conv : False\n",
      "52, block3c_expand_bn : False\n",
      "53, block3c_expand_activation : False\n",
      "54, block3c_project_conv : False\n",
      "55, block3c_project_bn : False\n",
      "56, block3c_drop : False\n",
      "57, block3c_add : False\n",
      "58, block3d_expand_conv : False\n",
      "59, block3d_expand_bn : False\n",
      "60, block3d_expand_activation : False\n",
      "61, block3d_project_conv : False\n",
      "62, block3d_project_bn : False\n",
      "63, block3d_drop : False\n",
      "64, block3d_add : False\n",
      "65, block4a_expand_conv : False\n",
      "66, block4a_expand_bn : False\n",
      "67, block4a_expand_activation : False\n",
      "68, block4a_dwconv2 : False\n",
      "69, block4a_bn : False\n",
      "70, block4a_activation : False\n",
      "71, block4a_se_squeeze : False\n",
      "72, block4a_se_reshape : False\n",
      "73, block4a_se_reduce : False\n",
      "74, block4a_se_expand : False\n",
      "75, block4a_se_excite : False\n",
      "76, block4a_project_conv : False\n",
      "77, block4a_project_bn : False\n",
      "78, block4b_expand_conv : False\n",
      "79, block4b_expand_bn : False\n",
      "80, block4b_expand_activation : False\n",
      "81, block4b_dwconv2 : False\n",
      "82, block4b_bn : False\n",
      "83, block4b_activation : False\n",
      "84, block4b_se_squeeze : False\n",
      "85, block4b_se_reshape : False\n",
      "86, block4b_se_reduce : False\n",
      "87, block4b_se_expand : False\n",
      "88, block4b_se_excite : False\n",
      "89, block4b_project_conv : False\n",
      "90, block4b_project_bn : False\n",
      "91, block4b_drop : False\n",
      "92, block4b_add : False\n",
      "93, block4c_expand_conv : False\n",
      "94, block4c_expand_bn : False\n",
      "95, block4c_expand_activation : False\n",
      "96, block4c_dwconv2 : False\n",
      "97, block4c_bn : False\n",
      "98, block4c_activation : False\n",
      "99, block4c_se_squeeze : False\n",
      "100, block4c_se_reshape : False\n",
      "101, block4c_se_reduce : False\n",
      "102, block4c_se_expand : False\n",
      "103, block4c_se_excite : False\n",
      "104, block4c_project_conv : False\n",
      "105, block4c_project_bn : False\n",
      "106, block4c_drop : False\n",
      "107, block4c_add : False\n",
      "108, block4d_expand_conv : False\n",
      "109, block4d_expand_bn : False\n",
      "110, block4d_expand_activation : False\n",
      "111, block4d_dwconv2 : False\n",
      "112, block4d_bn : False\n",
      "113, block4d_activation : False\n",
      "114, block4d_se_squeeze : False\n",
      "115, block4d_se_reshape : False\n",
      "116, block4d_se_reduce : False\n",
      "117, block4d_se_expand : False\n",
      "118, block4d_se_excite : False\n",
      "119, block4d_project_conv : False\n",
      "120, block4d_project_bn : False\n",
      "121, block4d_drop : False\n",
      "122, block4d_add : False\n",
      "123, block4e_expand_conv : False\n",
      "124, block4e_expand_bn : False\n",
      "125, block4e_expand_activation : False\n",
      "126, block4e_dwconv2 : False\n",
      "127, block4e_bn : False\n",
      "128, block4e_activation : False\n",
      "129, block4e_se_squeeze : False\n",
      "130, block4e_se_reshape : False\n",
      "131, block4e_se_reduce : False\n",
      "132, block4e_se_expand : False\n",
      "133, block4e_se_excite : False\n",
      "134, block4e_project_conv : False\n",
      "135, block4e_project_bn : False\n",
      "136, block4e_drop : False\n",
      "137, block4e_add : False\n",
      "138, block4f_expand_conv : False\n",
      "139, block4f_expand_bn : False\n",
      "140, block4f_expand_activation : False\n",
      "141, block4f_dwconv2 : False\n",
      "142, block4f_bn : False\n",
      "143, block4f_activation : False\n",
      "144, block4f_se_squeeze : False\n",
      "145, block4f_se_reshape : False\n",
      "146, block4f_se_reduce : False\n",
      "147, block4f_se_expand : False\n",
      "148, block4f_se_excite : False\n",
      "149, block4f_project_conv : False\n",
      "150, block4f_project_bn : False\n",
      "151, block4f_drop : False\n",
      "152, block4f_add : False\n",
      "153, block5a_expand_conv : False\n",
      "154, block5a_expand_bn : False\n",
      "155, block5a_expand_activation : False\n",
      "156, block5a_dwconv2 : False\n",
      "157, block5a_bn : False\n",
      "158, block5a_activation : False\n",
      "159, block5a_se_squeeze : False\n",
      "160, block5a_se_reshape : False\n",
      "161, block5a_se_reduce : False\n",
      "162, block5a_se_expand : False\n",
      "163, block5a_se_excite : False\n",
      "164, block5a_project_conv : False\n",
      "165, block5a_project_bn : False\n",
      "166, block5b_expand_conv : False\n",
      "167, block5b_expand_bn : False\n",
      "168, block5b_expand_activation : False\n",
      "169, block5b_dwconv2 : False\n",
      "170, block5b_bn : False\n",
      "171, block5b_activation : False\n",
      "172, block5b_se_squeeze : False\n",
      "173, block5b_se_reshape : False\n",
      "174, block5b_se_reduce : False\n",
      "175, block5b_se_expand : False\n",
      "176, block5b_se_excite : False\n",
      "177, block5b_project_conv : False\n",
      "178, block5b_project_bn : False\n",
      "179, block5b_drop : False\n",
      "180, block5b_add : False\n",
      "181, block5c_expand_conv : False\n",
      "182, block5c_expand_bn : False\n",
      "183, block5c_expand_activation : False\n",
      "184, block5c_dwconv2 : False\n",
      "185, block5c_bn : False\n",
      "186, block5c_activation : False\n",
      "187, block5c_se_squeeze : False\n",
      "188, block5c_se_reshape : False\n",
      "189, block5c_se_reduce : False\n",
      "190, block5c_se_expand : False\n",
      "191, block5c_se_excite : False\n",
      "192, block5c_project_conv : False\n",
      "193, block5c_project_bn : False\n",
      "194, block5c_drop : False\n",
      "195, block5c_add : False\n",
      "196, block5d_expand_conv : False\n",
      "197, block5d_expand_bn : False\n",
      "198, block5d_expand_activation : False\n",
      "199, block5d_dwconv2 : False\n",
      "200, block5d_bn : False\n",
      "201, block5d_activation : False\n",
      "202, block5d_se_squeeze : False\n",
      "203, block5d_se_reshape : False\n",
      "204, block5d_se_reduce : False\n",
      "205, block5d_se_expand : False\n",
      "206, block5d_se_excite : False\n",
      "207, block5d_project_conv : False\n",
      "208, block5d_project_bn : False\n",
      "209, block5d_drop : False\n",
      "210, block5d_add : False\n",
      "211, block5e_expand_conv : False\n",
      "212, block5e_expand_bn : False\n",
      "213, block5e_expand_activation : False\n",
      "214, block5e_dwconv2 : False\n",
      "215, block5e_bn : False\n",
      "216, block5e_activation : False\n",
      "217, block5e_se_squeeze : False\n",
      "218, block5e_se_reshape : False\n",
      "219, block5e_se_reduce : False\n",
      "220, block5e_se_expand : False\n",
      "221, block5e_se_excite : False\n",
      "222, block5e_project_conv : False\n",
      "223, block5e_project_bn : False\n",
      "224, block5e_drop : False\n",
      "225, block5e_add : False\n",
      "226, block5f_expand_conv : False\n",
      "227, block5f_expand_bn : False\n",
      "228, block5f_expand_activation : False\n",
      "229, block5f_dwconv2 : False\n",
      "230, block5f_bn : False\n",
      "231, block5f_activation : False\n",
      "232, block5f_se_squeeze : False\n",
      "233, block5f_se_reshape : False\n",
      "234, block5f_se_reduce : False\n",
      "235, block5f_se_expand : False\n",
      "236, block5f_se_excite : False\n",
      "237, block5f_project_conv : False\n",
      "238, block5f_project_bn : False\n",
      "239, block5f_drop : False\n",
      "240, block5f_add : False\n",
      "241, block5g_expand_conv : False\n",
      "242, block5g_expand_bn : False\n",
      "243, block5g_expand_activation : False\n",
      "244, block5g_dwconv2 : False\n",
      "245, block5g_bn : False\n",
      "246, block5g_activation : False\n",
      "247, block5g_se_squeeze : False\n",
      "248, block5g_se_reshape : False\n",
      "249, block5g_se_reduce : False\n",
      "250, block5g_se_expand : False\n",
      "251, block5g_se_excite : False\n",
      "252, block5g_project_conv : False\n",
      "253, block5g_project_bn : False\n",
      "254, block5g_drop : False\n",
      "255, block5g_add : False\n",
      "256, block5h_expand_conv : False\n",
      "257, block5h_expand_bn : False\n",
      "258, block5h_expand_activation : False\n",
      "259, block5h_dwconv2 : False\n",
      "260, block5h_bn : False\n",
      "261, block5h_activation : False\n",
      "262, block5h_se_squeeze : False\n",
      "263, block5h_se_reshape : False\n",
      "264, block5h_se_reduce : False\n",
      "265, block5h_se_expand : False\n",
      "266, block5h_se_excite : False\n",
      "267, block5h_project_conv : False\n",
      "268, block5h_project_bn : False\n",
      "269, block5h_drop : False\n",
      "270, block5h_add : False\n",
      "271, block5i_expand_conv : False\n",
      "272, block5i_expand_bn : False\n",
      "273, block5i_expand_activation : False\n",
      "274, block5i_dwconv2 : False\n",
      "275, block5i_bn : False\n",
      "276, block5i_activation : False\n",
      "277, block5i_se_squeeze : False\n",
      "278, block5i_se_reshape : False\n",
      "279, block5i_se_reduce : False\n",
      "280, block5i_se_expand : False\n",
      "281, block5i_se_excite : False\n",
      "282, block5i_project_conv : False\n",
      "283, block5i_project_bn : False\n",
      "284, block5i_drop : False\n",
      "285, block5i_add : False\n",
      "286, block6a_expand_conv : False\n",
      "287, block6a_expand_bn : False\n",
      "288, block6a_expand_activation : False\n",
      "289, block6a_dwconv2 : False\n",
      "290, block6a_bn : False\n",
      "291, block6a_activation : False\n",
      "292, block6a_se_squeeze : False\n",
      "293, block6a_se_reshape : False\n",
      "294, block6a_se_reduce : False\n",
      "295, block6a_se_expand : False\n",
      "296, block6a_se_excite : False\n",
      "297, block6a_project_conv : False\n",
      "298, block6a_project_bn : False\n",
      "299, block6b_expand_conv : False\n",
      "300, block6b_expand_bn : False\n",
      "301, block6b_expand_activation : False\n",
      "302, block6b_dwconv2 : False\n",
      "303, block6b_bn : False\n",
      "304, block6b_activation : False\n",
      "305, block6b_se_squeeze : False\n",
      "306, block6b_se_reshape : False\n",
      "307, block6b_se_reduce : False\n",
      "308, block6b_se_expand : False\n",
      "309, block6b_se_excite : False\n",
      "310, block6b_project_conv : False\n",
      "311, block6b_project_bn : False\n",
      "312, block6b_drop : False\n",
      "313, block6b_add : False\n",
      "314, block6c_expand_conv : False\n",
      "315, block6c_expand_bn : False\n",
      "316, block6c_expand_activation : False\n",
      "317, block6c_dwconv2 : False\n",
      "318, block6c_bn : False\n",
      "319, block6c_activation : False\n",
      "320, block6c_se_squeeze : False\n",
      "321, block6c_se_reshape : False\n",
      "322, block6c_se_reduce : False\n",
      "323, block6c_se_expand : False\n",
      "324, block6c_se_excite : False\n",
      "325, block6c_project_conv : False\n",
      "326, block6c_project_bn : False\n",
      "327, block6c_drop : False\n",
      "328, block6c_add : False\n",
      "329, block6d_expand_conv : False\n",
      "330, block6d_expand_bn : False\n",
      "331, block6d_expand_activation : False\n",
      "332, block6d_dwconv2 : False\n",
      "333, block6d_bn : False\n",
      "334, block6d_activation : False\n",
      "335, block6d_se_squeeze : False\n",
      "336, block6d_se_reshape : False\n",
      "337, block6d_se_reduce : False\n",
      "338, block6d_se_expand : False\n",
      "339, block6d_se_excite : False\n",
      "340, block6d_project_conv : False\n",
      "341, block6d_project_bn : False\n",
      "342, block6d_drop : False\n",
      "343, block6d_add : False\n",
      "344, block6e_expand_conv : False\n",
      "345, block6e_expand_bn : False\n",
      "346, block6e_expand_activation : False\n",
      "347, block6e_dwconv2 : False\n",
      "348, block6e_bn : False\n",
      "349, block6e_activation : False\n",
      "350, block6e_se_squeeze : False\n",
      "351, block6e_se_reshape : False\n",
      "352, block6e_se_reduce : False\n",
      "353, block6e_se_expand : False\n",
      "354, block6e_se_excite : False\n",
      "355, block6e_project_conv : False\n",
      "356, block6e_project_bn : False\n",
      "357, block6e_drop : False\n",
      "358, block6e_add : False\n",
      "359, block6f_expand_conv : True\n",
      "360, block6f_expand_bn : False\n",
      "361, block6f_expand_activation : True\n",
      "362, block6f_dwconv2 : True\n",
      "363, block6f_bn : False\n",
      "364, block6f_activation : True\n",
      "365, block6f_se_squeeze : True\n",
      "366, block6f_se_reshape : True\n",
      "367, block6f_se_reduce : True\n",
      "368, block6f_se_expand : True\n",
      "369, block6f_se_excite : True\n",
      "370, block6f_project_conv : True\n",
      "371, block6f_project_bn : False\n",
      "372, block6f_drop : True\n",
      "373, block6f_add : True\n",
      "374, block6g_expand_conv : True\n",
      "375, block6g_expand_bn : False\n",
      "376, block6g_expand_activation : True\n",
      "377, block6g_dwconv2 : True\n",
      "378, block6g_bn : False\n",
      "379, block6g_activation : True\n",
      "380, block6g_se_squeeze : True\n",
      "381, block6g_se_reshape : True\n",
      "382, block6g_se_reduce : True\n",
      "383, block6g_se_expand : True\n",
      "384, block6g_se_excite : True\n",
      "385, block6g_project_conv : True\n",
      "386, block6g_project_bn : False\n",
      "387, block6g_drop : True\n",
      "388, block6g_add : True\n",
      "389, block6h_expand_conv : True\n",
      "390, block6h_expand_bn : False\n",
      "391, block6h_expand_activation : True\n",
      "392, block6h_dwconv2 : True\n",
      "393, block6h_bn : False\n",
      "394, block6h_activation : True\n",
      "395, block6h_se_squeeze : True\n",
      "396, block6h_se_reshape : True\n",
      "397, block6h_se_reduce : True\n",
      "398, block6h_se_expand : True\n",
      "399, block6h_se_excite : True\n",
      "400, block6h_project_conv : True\n",
      "401, block6h_project_bn : False\n",
      "402, block6h_drop : True\n",
      "403, block6h_add : True\n",
      "404, block6i_expand_conv : True\n",
      "405, block6i_expand_bn : False\n",
      "406, block6i_expand_activation : True\n",
      "407, block6i_dwconv2 : True\n",
      "408, block6i_bn : False\n",
      "409, block6i_activation : True\n",
      "410, block6i_se_squeeze : True\n",
      "411, block6i_se_reshape : True\n",
      "412, block6i_se_reduce : True\n",
      "413, block6i_se_expand : True\n",
      "414, block6i_se_excite : True\n",
      "415, block6i_project_conv : True\n",
      "416, block6i_project_bn : False\n",
      "417, block6i_drop : True\n",
      "418, block6i_add : True\n",
      "419, block6j_expand_conv : True\n",
      "420, block6j_expand_bn : False\n",
      "421, block6j_expand_activation : True\n",
      "422, block6j_dwconv2 : True\n",
      "423, block6j_bn : False\n",
      "424, block6j_activation : True\n",
      "425, block6j_se_squeeze : True\n",
      "426, block6j_se_reshape : True\n",
      "427, block6j_se_reduce : True\n",
      "428, block6j_se_expand : True\n",
      "429, block6j_se_excite : True\n",
      "430, block6j_project_conv : True\n",
      "431, block6j_project_bn : False\n",
      "432, block6j_drop : True\n",
      "433, block6j_add : True\n",
      "434, block6k_expand_conv : True\n",
      "435, block6k_expand_bn : False\n",
      "436, block6k_expand_activation : True\n",
      "437, block6k_dwconv2 : True\n",
      "438, block6k_bn : False\n",
      "439, block6k_activation : True\n",
      "440, block6k_se_squeeze : True\n",
      "441, block6k_se_reshape : True\n",
      "442, block6k_se_reduce : True\n",
      "443, block6k_se_expand : True\n",
      "444, block6k_se_excite : True\n",
      "445, block6k_project_conv : True\n",
      "446, block6k_project_bn : False\n",
      "447, block6k_drop : True\n",
      "448, block6k_add : True\n",
      "449, block6l_expand_conv : True\n",
      "450, block6l_expand_bn : False\n",
      "451, block6l_expand_activation : True\n",
      "452, block6l_dwconv2 : True\n",
      "453, block6l_bn : False\n",
      "454, block6l_activation : True\n",
      "455, block6l_se_squeeze : True\n",
      "456, block6l_se_reshape : True\n",
      "457, block6l_se_reduce : True\n",
      "458, block6l_se_expand : True\n",
      "459, block6l_se_excite : True\n",
      "460, block6l_project_conv : True\n",
      "461, block6l_project_bn : False\n",
      "462, block6l_drop : True\n",
      "463, block6l_add : True\n",
      "464, block6m_expand_conv : True\n",
      "465, block6m_expand_bn : False\n",
      "466, block6m_expand_activation : True\n",
      "467, block6m_dwconv2 : True\n",
      "468, block6m_bn : False\n",
      "469, block6m_activation : True\n",
      "470, block6m_se_squeeze : True\n",
      "471, block6m_se_reshape : True\n",
      "472, block6m_se_reduce : True\n",
      "473, block6m_se_expand : True\n",
      "474, block6m_se_excite : True\n",
      "475, block6m_project_conv : True\n",
      "476, block6m_project_bn : False\n",
      "477, block6m_drop : True\n",
      "478, block6m_add : True\n",
      "479, block6n_expand_conv : True\n",
      "480, block6n_expand_bn : False\n",
      "481, block6n_expand_activation : True\n",
      "482, block6n_dwconv2 : True\n",
      "483, block6n_bn : False\n",
      "484, block6n_activation : True\n",
      "485, block6n_se_squeeze : True\n",
      "486, block6n_se_reshape : True\n",
      "487, block6n_se_reduce : True\n",
      "488, block6n_se_expand : True\n",
      "489, block6n_se_excite : True\n",
      "490, block6n_project_conv : True\n",
      "491, block6n_project_bn : False\n",
      "492, block6n_drop : True\n",
      "493, block6n_add : True\n",
      "494, block6o_expand_conv : True\n",
      "495, block6o_expand_bn : False\n",
      "496, block6o_expand_activation : True\n",
      "497, block6o_dwconv2 : True\n",
      "498, block6o_bn : False\n",
      "499, block6o_activation : True\n",
      "500, block6o_se_squeeze : True\n",
      "501, block6o_se_reshape : True\n",
      "502, block6o_se_reduce : True\n",
      "503, block6o_se_expand : True\n",
      "504, block6o_se_excite : True\n",
      "505, block6o_project_conv : True\n",
      "506, block6o_project_bn : False\n",
      "507, block6o_drop : True\n",
      "508, block6o_add : True\n",
      "509, top_conv : True\n",
      "510, top_bn : False\n",
      "511, top_activation : True\n",
      "512, avg_pool : True\n",
      "513, top_dropout : True\n",
      "514, pred : True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "  layer.trainable = False\n",
    "for layer in model.layers[-156:]:\n",
    "      if not isinstance(layer, layers.BatchNormalization):\n",
    "          layer.trainable = True\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "  print(f\"{i}, {layer.name} : {layer.trainable}\")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss=categorical_focal_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 06:46:56.389062: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inEfficientNet/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.7487\n",
      "Epoch 1: val_accuracy improved from 0.70708 to 0.71880, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 584s 744ms/step - loss: 0.0016 - accuracy: 0.7487 - val_loss: 0.0031 - val_accuracy: 0.7188\n",
      "Epoch 2/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.7711\n",
      "Epoch 2: val_accuracy improved from 0.71880 to 0.72889, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 552s 734ms/step - loss: 0.0011 - accuracy: 0.7711 - val_loss: 0.0026 - val_accuracy: 0.7289\n",
      "Epoch 3/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 8.9010e-04 - accuracy: 0.7789\n",
      "Epoch 3: val_accuracy improved from 0.72889 to 0.73068, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 558s 742ms/step - loss: 8.9010e-04 - accuracy: 0.7789 - val_loss: 0.0022 - val_accuracy: 0.7307\n",
      "Epoch 4/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 7.7601e-04 - accuracy: 0.7815\n",
      "Epoch 4: val_accuracy improved from 0.73068 to 0.74337, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 557s 741ms/step - loss: 7.7601e-04 - accuracy: 0.7815 - val_loss: 0.0019 - val_accuracy: 0.7434\n",
      "Epoch 5/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 6.7144e-04 - accuracy: 0.7911\n",
      "Epoch 5: val_accuracy improved from 0.74337 to 0.74418, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 558s 741ms/step - loss: 6.7144e-04 - accuracy: 0.7911 - val_loss: 0.0018 - val_accuracy: 0.7442\n",
      "Epoch 6/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 5.9142e-04 - accuracy: 0.7967\n",
      "Epoch 6: val_accuracy improved from 0.74418 to 0.74955, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 555s 737ms/step - loss: 5.9142e-04 - accuracy: 0.7967 - val_loss: 0.0018 - val_accuracy: 0.7496\n",
      "Epoch 7/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 5.1212e-04 - accuracy: 0.8137\n",
      "Epoch 7: val_accuracy did not improve from 0.74955\n",
      "752/752 [==============================] - 510s 678ms/step - loss: 5.1212e-04 - accuracy: 0.8137 - val_loss: 0.0016 - val_accuracy: 0.7466\n",
      "Epoch 8/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 4.7744e-04 - accuracy: 0.8136\n",
      "Epoch 8: val_accuracy improved from 0.74955 to 0.75037, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 567s 753ms/step - loss: 4.7744e-04 - accuracy: 0.8136 - val_loss: 0.0016 - val_accuracy: 0.7504\n",
      "Epoch 9/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 4.2057e-04 - accuracy: 0.8224\n",
      "Epoch 9: val_accuracy improved from 0.75037 to 0.76404, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 558s 741ms/step - loss: 4.2057e-04 - accuracy: 0.8224 - val_loss: 0.0015 - val_accuracy: 0.7640\n",
      "Epoch 10/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 3.6877e-04 - accuracy: 0.8409\n",
      "Epoch 10: val_accuracy improved from 0.76404 to 0.76713, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 557s 740ms/step - loss: 3.6877e-04 - accuracy: 0.8409 - val_loss: 0.0015 - val_accuracy: 0.7671\n",
      "Epoch 11/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 3.0939e-04 - accuracy: 0.8533\n",
      "Epoch 11: val_accuracy improved from 0.76713 to 0.77787, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 557s 741ms/step - loss: 3.0939e-04 - accuracy: 0.8533 - val_loss: 0.0015 - val_accuracy: 0.7779\n",
      "Epoch 12/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.7700e-04 - accuracy: 0.8636\n",
      "Epoch 12: val_accuracy improved from 0.77787 to 0.78942, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 556s 739ms/step - loss: 2.7700e-04 - accuracy: 0.8636 - val_loss: 0.0015 - val_accuracy: 0.7894\n",
      "Epoch 13/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.3668e-04 - accuracy: 0.8763\n",
      "Epoch 13: val_accuracy improved from 0.78942 to 0.79707, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 559s 743ms/step - loss: 2.3668e-04 - accuracy: 0.8763 - val_loss: 0.0015 - val_accuracy: 0.7971\n",
      "Epoch 14/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.1150e-04 - accuracy: 0.8812\n",
      "Epoch 14: val_accuracy improved from 0.79707 to 0.79772, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 559s 743ms/step - loss: 2.1150e-04 - accuracy: 0.8812 - val_loss: 0.0014 - val_accuracy: 0.7977\n",
      "Epoch 15/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8106e-04 - accuracy: 0.8939\n",
      "Epoch 15: val_accuracy improved from 0.79772 to 0.80000, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 568s 756ms/step - loss: 1.8106e-04 - accuracy: 0.8939 - val_loss: 0.0014 - val_accuracy: 0.8000\n",
      "Epoch 16/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.6748e-04 - accuracy: 0.9009\n",
      "Epoch 16: val_accuracy improved from 0.80000 to 0.80439, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 570s 758ms/step - loss: 1.6748e-04 - accuracy: 0.9009 - val_loss: 0.0014 - val_accuracy: 0.8044\n",
      "Epoch 17/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.5361e-04 - accuracy: 0.9019\n",
      "Epoch 17: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 505s 671ms/step - loss: 1.5361e-04 - accuracy: 0.9019 - val_loss: 0.0014 - val_accuracy: 0.8003\n",
      "Epoch 18/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.6555e-04 - accuracy: 0.8978\n",
      "Epoch 18: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 505s 672ms/step - loss: 1.6555e-04 - accuracy: 0.8978 - val_loss: 0.0013 - val_accuracy: 0.8011\n",
      "Epoch 19/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.6335e-04 - accuracy: 0.8969\n",
      "Epoch 19: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 508s 675ms/step - loss: 1.6335e-04 - accuracy: 0.8969 - val_loss: 0.0014 - val_accuracy: 0.8005\n",
      "Epoch 20/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8201e-04 - accuracy: 0.8929\n",
      "Epoch 20: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 511s 679ms/step - loss: 1.8201e-04 - accuracy: 0.8929 - val_loss: 0.0014 - val_accuracy: 0.7915\n",
      "Epoch 21/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8374e-04 - accuracy: 0.8901\n",
      "Epoch 21: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 515s 684ms/step - loss: 1.8374e-04 - accuracy: 0.8901 - val_loss: 0.0013 - val_accuracy: 0.7930\n",
      "Epoch 22/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.9832e-04 - accuracy: 0.8853\n",
      "Epoch 22: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 512s 681ms/step - loss: 1.9832e-04 - accuracy: 0.8853 - val_loss: 0.0013 - val_accuracy: 0.7842\n",
      "Epoch 23/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.1676e-04 - accuracy: 0.8803\n",
      "Epoch 23: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 507s 674ms/step - loss: 2.1676e-04 - accuracy: 0.8803 - val_loss: 0.0014 - val_accuracy: 0.7884\n",
      "Epoch 24/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.1564e-04 - accuracy: 0.8796\n",
      "Epoch 24: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 517s 687ms/step - loss: 2.1564e-04 - accuracy: 0.8796 - val_loss: 0.0015 - val_accuracy: 0.7943\n",
      "Epoch 25/25\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.2080e-04 - accuracy: 0.8812\n",
      "Epoch 25: val_accuracy did not improve from 0.80439\n",
      "752/752 [==============================] - 539s 716ms/step - loss: 2.2080e-04 - accuracy: 0.8812 - val_loss: 0.0014 - val_accuracy: 0.7972\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the image generator for training and validation\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=len(trainGen),\n",
    "    validation_data=valGen,\n",
    "    validation_steps=len(valGen),\n",
    "    callbacks=[model_checkpoint]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clr\n",
    "lr_schedule = tfa.optimizers.TriangularCyclicalLearningRate(\n",
    "    initial_learning_rate=1e-5,\n",
    "    maximal_learning_rate=1e-4,\n",
    "    step_size=1504,\n",
    "    scale_mode=\"cycle\",\n",
    "    name=\"CyclicScheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.7597e-04 - accuracy: 0.8973\n",
      "Epoch 1: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 660s 877ms/step - loss: 1.7597e-04 - accuracy: 0.8973 - val_loss: 0.0014 - val_accuracy: 0.8011\n",
      "Epoch 2/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8539e-04 - accuracy: 0.8912\n",
      "Epoch 2: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 696s 925ms/step - loss: 1.8539e-04 - accuracy: 0.8912 - val_loss: 0.0015 - val_accuracy: 0.7992\n",
      "Epoch 3/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8903e-04 - accuracy: 0.8896\n",
      "Epoch 3: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 676s 899ms/step - loss: 1.8903e-04 - accuracy: 0.8896 - val_loss: 0.0013 - val_accuracy: 0.7943\n",
      "Epoch 4/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.0195e-04 - accuracy: 0.8862\n",
      "Epoch 4: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 1335s 2s/step - loss: 2.0195e-04 - accuracy: 0.8862 - val_loss: 0.0015 - val_accuracy: 0.7990\n",
      "Epoch 5/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.1072e-04 - accuracy: 0.8834\n",
      "Epoch 5: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 549s 729ms/step - loss: 2.1072e-04 - accuracy: 0.8834 - val_loss: 0.0015 - val_accuracy: 0.7967\n",
      "Epoch 6/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.1865e-04 - accuracy: 0.8813\n",
      "Epoch 6: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 729s 969ms/step - loss: 2.1865e-04 - accuracy: 0.8813 - val_loss: 0.0015 - val_accuracy: 0.7881\n",
      "Epoch 7/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 2.2079e-04 - accuracy: 0.8797\n",
      "Epoch 7: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 780s 1s/step - loss: 2.2079e-04 - accuracy: 0.8797 - val_loss: 0.0015 - val_accuracy: 0.7932\n",
      "Epoch 8/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.8326e-04 - accuracy: 0.8897\n",
      "Epoch 8: val_accuracy did not improve from 0.80163\n",
      "752/752 [==============================] - 766s 1s/step - loss: 1.8326e-04 - accuracy: 0.8897 - val_loss: 0.0014 - val_accuracy: 0.8015\n",
      "Epoch 9/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.6367e-04 - accuracy: 0.8984\n",
      "Epoch 9: val_accuracy improved from 0.80163 to 0.80260, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 907s 1s/step - loss: 1.6367e-04 - accuracy: 0.8984 - val_loss: 0.0014 - val_accuracy: 0.8026\n",
      "Epoch 10/10\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.3680e-04 - accuracy: 0.9071\n",
      "Epoch 10: val_accuracy improved from 0.80260 to 0.80797, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 742s 987ms/step - loss: 1.3680e-04 - accuracy: 0.9071 - val_loss: 0.0013 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the image generator for training and validation\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(trainGen),\n",
    "    validation_data=valGen,\n",
    "    validation_steps=len(valGen),\n",
    "    callbacks=[model_checkpoint]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.1474e-04 - accuracy: 0.9164\n",
      "Epoch 1: val_accuracy improved from 0.80797 to 0.81058, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 802s 1s/step - loss: 1.1474e-04 - accuracy: 0.9164 - val_loss: 0.0013 - val_accuracy: 0.8106\n",
      "Epoch 2/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0917e-04 - accuracy: 0.9206\n",
      "Epoch 2: val_accuracy improved from 0.81058 to 0.81318, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 892s 1s/step - loss: 1.0917e-04 - accuracy: 0.9206 - val_loss: 0.0013 - val_accuracy: 0.8132\n",
      "Epoch 3/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 9.6632e-05 - accuracy: 0.9272\n",
      "Epoch 3: val_accuracy improved from 0.81318 to 0.81806, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 746s 991ms/step - loss: 9.6632e-05 - accuracy: 0.9272 - val_loss: 0.0013 - val_accuracy: 0.8181\n",
      "Epoch 4/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 8.4546e-05 - accuracy: 0.9322\n",
      "Epoch 4: val_accuracy improved from 0.81806 to 0.82197, saving model to /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)\n",
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/halwa/fyp/Training/Checkpoints/ScratchEffNetV2S(588Species)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 754s 1s/step - loss: 8.4546e-05 - accuracy: 0.9322 - val_loss: 0.0012 - val_accuracy: 0.8220\n",
      "Epoch 5/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 8.0396e-05 - accuracy: 0.9349\n",
      "Epoch 5: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 751s 999ms/step - loss: 8.0396e-05 - accuracy: 0.9349 - val_loss: 0.0012 - val_accuracy: 0.8186\n",
      "Epoch 6/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 7.9622e-05 - accuracy: 0.9337\n",
      "Epoch 6: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 735s 977ms/step - loss: 7.9622e-05 - accuracy: 0.9337 - val_loss: 0.0013 - val_accuracy: 0.8210\n",
      "Epoch 7/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 9.2216e-05 - accuracy: 0.9298\n",
      "Epoch 7: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 735s 977ms/step - loss: 9.2216e-05 - accuracy: 0.9298 - val_loss: 0.0013 - val_accuracy: 0.8150\n",
      "Epoch 8/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0059e-04 - accuracy: 0.9246\n",
      "Epoch 8: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 738s 981ms/step - loss: 1.0059e-04 - accuracy: 0.9246 - val_loss: 0.0012 - val_accuracy: 0.8164\n",
      "Epoch 9/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0466e-04 - accuracy: 0.9254\n",
      "Epoch 9: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 728s 967ms/step - loss: 1.0466e-04 - accuracy: 0.9254 - val_loss: 0.0013 - val_accuracy: 0.8163\n",
      "Epoch 10/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.2244e-04 - accuracy: 0.9152\n",
      "Epoch 10: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 796s 1s/step - loss: 1.2244e-04 - accuracy: 0.9152 - val_loss: 0.0014 - val_accuracy: 0.7980\n",
      "Epoch 11/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.3257e-04 - accuracy: 0.9118\n",
      "Epoch 11: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 708s 941ms/step - loss: 1.3257e-04 - accuracy: 0.9118 - val_loss: 0.0014 - val_accuracy: 0.8015\n",
      "Epoch 12/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.2578e-04 - accuracy: 0.9141\n",
      "Epoch 12: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 558s 741ms/step - loss: 1.2578e-04 - accuracy: 0.9141 - val_loss: 0.0015 - val_accuracy: 0.8099\n",
      "Epoch 13/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.3424e-04 - accuracy: 0.9130\n",
      "Epoch 13: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 609s 810ms/step - loss: 1.3424e-04 - accuracy: 0.9130 - val_loss: 0.0014 - val_accuracy: 0.8103\n",
      "Epoch 14/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.2723e-04 - accuracy: 0.9170\n",
      "Epoch 14: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 532s 706ms/step - loss: 1.2723e-04 - accuracy: 0.9170 - val_loss: 0.0013 - val_accuracy: 0.8192\n",
      "Epoch 15/15\n",
      "752/752 [==============================] - ETA: 0s - loss: 1.0803e-04 - accuracy: 0.9214\n",
      "Epoch 15: val_accuracy did not improve from 0.82197\n",
      "752/752 [==============================] - 519s 689ms/step - loss: 1.0803e-04 - accuracy: 0.9214 - val_loss: 0.0013 - val_accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the image generator for training and validation\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(trainGen),\n",
    "    validation_data=valGen,\n",
    "    validation_steps=len(valGen),\n",
    "    callbacks=[model_checkpoint]  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
